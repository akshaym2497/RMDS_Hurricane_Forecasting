{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RI Prediction Model\n",
    "\n",
    "### Prediction of Hurricane Rapid Intensification\n",
    "\n",
    "Project Summary: Storms that undergo rapid intensification (RI) are associated with the highest forecat errors and larger economic losses.\n",
    "    To reduce the damage caused by the hurricane, accurate prediction of hurricane intensity is critical. This project aims to improve previous models that predict whether or not hurricane will experience RI within 24 hours.\n",
    "    \n",
    "Project Goal: Finding a model that effectively predicts whether the hurricane will or will not experience a Rapid Intensification (RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to build Machine Learning model for hurricane intensity forecast  \n",
    "import pandas as pd # For data manipulation and analysis\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np # For scientific computing\n",
    "\n",
    "#Machine Learning Tools\n",
    "import sklearn # For machine learning library\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#from sklearn.ensemble import ExtraTreesClassifier    # Extra tree classifier\n",
    "from sklearn.metrics import confusion_matrix # Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "from sklearn.metrics import brier_score_loss  # Compute the Brier score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import brier_score_loss  # Compute the Brier score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt  #plotting library\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE #SMOTE oversampling\n",
    "\n",
    "#Displaying More Rows\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data and Data Inspection\n",
    "\n",
    "Let's take a look closer at each data set. Few of the data characteristics that we are looking for:\n",
    "- column names\n",
    "- data type\n",
    "- number of rows\n",
    "- missing values (null)\n",
    "- plausible features that could impact survival rate\n",
    "- target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>VMX0</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>ID</th>\n",
       "      <th>DELV12</th>\n",
       "      <th>DELV24</th>\n",
       "      <th>DELV36</th>\n",
       "      <th>DELV48</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>OHC</th>\n",
       "      <th>TPW</th>\n",
       "      <th>PC2</th>\n",
       "      <th>U200</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>RSST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980727</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>11.3</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9999</td>\n",
       "      <td>6.3</td>\n",
       "      <td>103</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-101</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-58</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>55.7</td>\n",
       "      <td>-473</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980727</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-27.2</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9999</td>\n",
       "      <td>11.2</td>\n",
       "      <td>118</td>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-102</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>-360</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-29.2</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>116</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-105</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>56.9</td>\n",
       "      <td>-381</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-31.3</td>\n",
       "      <td>1008</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>91</td>\n",
       "      <td>71</td>\n",
       "      <td>57</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-100</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>-44</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>-481</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-33.3</td>\n",
       "      <td>1007</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-89</td>\n",
       "      <td>15</td>\n",
       "      <td>190</td>\n",
       "      <td>-46</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-516</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171108</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>34.6</td>\n",
       "      <td>-48.7</td>\n",
       "      <td>999</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>29</td>\n",
       "      <td>71</td>\n",
       "      <td>31</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-37</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>123</td>\n",
       "      <td>22.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>-35</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171108</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>36.4</td>\n",
       "      <td>-48.7</td>\n",
       "      <td>996</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>-5</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>10</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19</td>\n",
       "      <td>73</td>\n",
       "      <td>15</td>\n",
       "      <td>14.7</td>\n",
       "      <td>-28</td>\n",
       "      <td>0</td>\n",
       "      <td>969</td>\n",
       "      <td>90</td>\n",
       "      <td>21.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-121</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7402</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171108</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>38.3</td>\n",
       "      <td>-48.8</td>\n",
       "      <td>994</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>0</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-29</td>\n",
       "      <td>0</td>\n",
       "      <td>966</td>\n",
       "      <td>126</td>\n",
       "      <td>23.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-38</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171108</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>40.1</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>992</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>14</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>948</td>\n",
       "      <td>75</td>\n",
       "      <td>28.4</td>\n",
       "      <td>44.3</td>\n",
       "      <td>-166</td>\n",
       "      <td>21.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7404</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171109</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>41.8</td>\n",
       "      <td>-48.8</td>\n",
       "      <td>991</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "      <td>17</td>\n",
       "      <td>21.5</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>996</td>\n",
       "      <td>105</td>\n",
       "      <td>32.6</td>\n",
       "      <td>42.3</td>\n",
       "      <td>-137</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7405 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NAME    DATE  HOUR  VMX0   LAT   LON  MSLP        ID  DELV12  DELV24  \\\n",
       "0     ALEX  980727    12    25  11.3 -25.4  1009  AL011998       0       5   \n",
       "1     ALEX  980727    18    25  11.7 -27.2  1009  AL011998       0       5   \n",
       "2     ALEX  980728     0    25  12.2 -29.2  1009  AL011998       5      10   \n",
       "3     ALEX  980728     6    25  12.6 -31.3  1008  AL011998       5      10   \n",
       "4     ALEX  980728    12    30  12.9 -33.3  1007  AL011998       5       5   \n",
       "...    ...     ...   ...   ...   ...   ...   ...       ...     ...     ...   \n",
       "7400  RINA  171108     0    45  34.6 -48.7   999  AL192017       0       0   \n",
       "7401  RINA  171108     6    50  36.4 -48.7   996  AL192017      -5    9999   \n",
       "7402  RINA  171108    12    45  38.3 -48.8   994  AL192017       0    9999   \n",
       "7403  RINA  171108    18    45  40.1 -49.0   992  AL192017    9999    9999   \n",
       "7404  RINA  171109     0    45  41.8 -48.8   991  AL192017    9999    9999   \n",
       "\n",
       "      DELV36  DELV48   PER  SHRD  D200  RHLO  PX30  SDBT  POT  OHC   TPW  PC2  \\\n",
       "0         10      10  9999   6.3   103    68    72  13.8 -101   12     0  -58   \n",
       "1         10      10  9999  11.2   118    69    55  12.6 -102   17     0  -10   \n",
       "2         10      10     0   8.6   116    71    70  12.8 -105   21     0   -3   \n",
       "3         10      15     0  12.2    91    71    57  12.2 -100   29     0  -44   \n",
       "4          5      10     5  10.5    88    71    83  10.1  -89   15   190  -46   \n",
       "...      ...     ...   ...   ...   ...   ...   ...   ...  ...  ...   ...  ...   \n",
       "7400    9999    9999     5  20.5    29    71    31  24.3  -37    0  1000  123   \n",
       "7401    9999    9999    10  20.8    19    73    15  14.7  -28    0   969   90   \n",
       "7402    9999    9999     0  21.2    12    74     9  13.5  -29    0   966  126   \n",
       "7403    9999    9999    -5  22.5    14    70     7  11.5  -14    0   948   75   \n",
       "7404    9999    9999     0  23.8    38    71    17  21.5   43    0   996  105   \n",
       "\n",
       "      U200  TPWC  AVBT  RSST  \n",
       "0     -7.9  55.7  -473  27.4  \n",
       "1     -6.4  55.7  -360  27.4  \n",
       "2     -8.8  56.9  -381  27.4  \n",
       "3     -6.0  52.7  -481  27.2  \n",
       "4     -6.5  55.3  -516  27.1  \n",
       "...    ...   ...   ...   ...  \n",
       "7400  22.0  42.9   -35  23.5  \n",
       "7401  21.8  43.0  -121  22.9  \n",
       "7402  23.0  43.0   -38  22.7  \n",
       "7403  28.4  44.3  -166  21.3  \n",
       "7404  32.6  42.3  -137  17.4  \n",
       "\n",
       "[7405 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the location of the data\n",
    "fname='Dataset_SHIPS_RII_ATL.csv'\n",
    "#fname='Dataset_SHIPS_RII_EPAC.csv'\n",
    "\n",
    "# Read SHIPS data\n",
    "ships = pd.read_csv(fname)\n",
    "ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all 9999s as NaNs\n",
    "ships = ships.replace(9999,np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Counts all null values in each columns\n",
    "def count_null(data):\n",
    "    null_each_col={}\n",
    "\n",
    "    for col in data.columns:\n",
    "        null_count=data[col].isnull().sum()\n",
    "        null_each_col[col]=null_count\n",
    "    return null_each_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME': 0,\n",
       " 'DATE': 0,\n",
       " 'HOUR': 0,\n",
       " 'VMX0': 0,\n",
       " 'LAT': 0,\n",
       " 'LON': 0,\n",
       " 'MSLP': 0,\n",
       " 'ID': 0,\n",
       " 'DELV12': 718,\n",
       " 'DELV24': 1427,\n",
       " 'DELV36': 2082,\n",
       " 'DELV48': 2682,\n",
       " 'PER': 1456,\n",
       " 'SHRD': 0,\n",
       " 'D200': 0,\n",
       " 'RHLO': 0,\n",
       " 'PX30': 402,\n",
       " 'SDBT': 402,\n",
       " 'POT': 0,\n",
       " 'OHC': 19,\n",
       " 'TPW': 0,\n",
       " 'PC2': 387,\n",
       " 'U200': 0,\n",
       " 'TPWC': 0,\n",
       " 'AVBT': 402,\n",
       " 'RSST': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = count_null(ships)\n",
    "null_counts\n",
    "\n",
    "# There are a lot of null values in DELV12, DELV24, DELV36, DELV48, PER, PX30, SDBT, OHC, PC2, AVBT\n",
    "# DELV12, DELV24, DELV36, DELV48 will be dropped during the data cleaning since they will not be used as the predictor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Set-up\n",
    "\n",
    "Setting up RI threshold, train/forecast threshold, target variable/feature, and climatoloogy constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year range for training and validating\n",
    "year_train=['1998','2008']\n",
    "\n",
    "# Year range for forecast\n",
    "year_fcst=['2009','2017']\n",
    "\n",
    "# Variable name for predictand\n",
    "TargetName='DELV24'\n",
    "\n",
    "# Threshold of Rapid Intensification \n",
    "RIValue=30\n",
    "\n",
    "# Climatology of RI (30 kt) frequency at Atlantic basin (Kaplan et al. 2015)\n",
    "clim=0.125   #ATL 30 kt\n",
    "#clim=0.084   #EPAC 30 kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- Cleaning Date Column\n",
    "- Creating Target Column 'TAR'\n",
    "- Dropping all DELV Columns\n",
    "- Dropping all null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>VMX0</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>ID</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>OHC</th>\n",
       "      <th>TPW</th>\n",
       "      <th>PC2</th>\n",
       "      <th>U200</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>RSST</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-29.2</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>116</td>\n",
       "      <td>71</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-105</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>56.9</td>\n",
       "      <td>-381.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-31.3</td>\n",
       "      <td>1008</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>91</td>\n",
       "      <td>71</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-100</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>-481.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-33.3</td>\n",
       "      <td>1007</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>83.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-89</td>\n",
       "      <td>15.0</td>\n",
       "      <td>190</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-516.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-35.1</td>\n",
       "      <td>1006</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>44</td>\n",
       "      <td>72</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>-86</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>56.6</td>\n",
       "      <td>-270.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980729</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-36.8</td>\n",
       "      <td>1005</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>37</td>\n",
       "      <td>74</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-80</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>57.7</td>\n",
       "      <td>-443.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171108</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>34.6</td>\n",
       "      <td>-48.7</td>\n",
       "      <td>999</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>29</td>\n",
       "      <td>71</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171108</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>36.4</td>\n",
       "      <td>-48.7</td>\n",
       "      <td>996</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19</td>\n",
       "      <td>73</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>969</td>\n",
       "      <td>90.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7402</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171108</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>38.3</td>\n",
       "      <td>-48.8</td>\n",
       "      <td>994</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>966</td>\n",
       "      <td>126.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171108</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>40.1</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>992</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>14</td>\n",
       "      <td>70</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>948</td>\n",
       "      <td>75.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>44.3</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7404</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171109</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>41.8</td>\n",
       "      <td>-48.8</td>\n",
       "      <td>991</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>996</td>\n",
       "      <td>105.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>42.3</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5714 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NAME    DATE  HOUR  VMX0   LAT   LON  MSLP        ID   PER  SHRD  D200  \\\n",
       "2     ALEX  980728     0    25  12.2 -29.2  1009  AL011998   0.0   8.6   116   \n",
       "3     ALEX  980728     6    25  12.6 -31.3  1008  AL011998   0.0  12.2    91   \n",
       "4     ALEX  980728    12    30  12.9 -33.3  1007  AL011998   5.0  10.5    88   \n",
       "5     ALEX  980728    18    30  13.1 -35.1  1006  AL011998   5.0   9.7    44   \n",
       "6     ALEX  980729     0    35  13.3 -36.8  1005  AL011998   5.0   9.9    37   \n",
       "...    ...     ...   ...   ...   ...   ...   ...       ...   ...   ...   ...   \n",
       "7400  RINA  171108     0    45  34.6 -48.7   999  AL192017   5.0  20.5    29   \n",
       "7401  RINA  171108     6    50  36.4 -48.7   996  AL192017  10.0  20.8    19   \n",
       "7402  RINA  171108    12    45  38.3 -48.8   994  AL192017   0.0  21.2    12   \n",
       "7403  RINA  171108    18    45  40.1 -49.0   992  AL192017  -5.0  22.5    14   \n",
       "7404  RINA  171109     0    45  41.8 -48.8   991  AL192017   0.0  23.8    38   \n",
       "\n",
       "      RHLO  PX30  SDBT  POT   OHC   TPW    PC2  U200  TPWC   AVBT  RSST MONTH  \\\n",
       "2       71  70.0  12.8 -105  21.0     0   -3.0  -8.8  56.9 -381.0  27.4    07   \n",
       "3       71  57.0  12.2 -100  29.0     0  -44.0  -6.0  52.7 -481.0  27.2    07   \n",
       "4       71  83.0  10.1  -89  15.0   190  -46.0  -6.5  55.3 -516.0  27.1    07   \n",
       "5       72  35.0  15.9  -86  22.0    15   36.0  -7.2  56.6 -270.0  27.1    07   \n",
       "6       74  56.0  14.5  -80  24.0     0   -6.0 -10.3  57.7 -443.0  27.1    07   \n",
       "...    ...   ...   ...  ...   ...   ...    ...   ...   ...    ...   ...   ...   \n",
       "7400    71  31.0  24.3  -37   0.0  1000  123.0  22.0  42.9  -35.0  23.5    11   \n",
       "7401    73  15.0  14.7  -28   0.0   969   90.0  21.8  43.0 -121.0  22.9    11   \n",
       "7402    74   9.0  13.5  -29   0.0   966  126.0  23.0  43.0  -38.0  22.7    11   \n",
       "7403    70   7.0  11.5  -14   0.0   948   75.0  28.4  44.3 -166.0  21.3    11   \n",
       "7404    71  17.0  21.5   43   0.0   996  105.0  32.6  42.3 -137.0  17.4    11   \n",
       "\n",
       "      YEAR  TAR  \n",
       "2     1998    0  \n",
       "3     1998    0  \n",
       "4     1998    0  \n",
       "5     1998    0  \n",
       "6     1998    0  \n",
       "...    ...  ...  \n",
       "7400  2017    0  \n",
       "7401  2017    0  \n",
       "7402  2017    0  \n",
       "7403  2017    0  \n",
       "7404  2017    0  \n",
       "\n",
       "[5714 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the date columns with 00 for the year 2000\n",
    "ships['DATE'] = ships['DATE'].apply(lambda x: str(x).zfill(6))\n",
    "\n",
    "# Extract month from date\n",
    "ships['MONTH'] = ships['DATE'].apply(lambda x: str(x)[2:4])\n",
    "\n",
    "# Extract year from date\n",
    "ships['YEAR'] = ships['DATE'].apply(lambda x: ('19' + str(x)[0:2]) if (str(x)[0:1]!= '0' and str(x)[0:1]!= '1') else ('20' + str(x)[0:2]))\n",
    "ships.head()\n",
    "\n",
    "# Set the target column\n",
    "ships['TAR'] = ships[TargetName].apply(lambda x: 1 if x >= RIValue else 0)\n",
    "\n",
    "# Dropping all DELV columns\n",
    "# - Dropping DELV columns before droping null values saved 1971 data points\n",
    "ships=ships.drop(['DELV12', 'DELV24', 'DELV36', 'DELV48'], axis=1)\n",
    "\n",
    "# drop NaNs\n",
    "ships=ships.dropna()\n",
    "ships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Grids for Data Sets, Sampling Methods, and Hyperparameters\n",
    "\n",
    "- Predictor Sets: Sets with different predictor features\n",
    "- Data Sets:      Data Sets with different sampling methods\n",
    "- Model Sets:     Different types of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictor Sets\n",
    "\n",
    "Predictor_Sets=[]\n",
    "\n",
    "# Adding different features into the list\n",
    "Predictor_Sets.append(('Set1', ['PER','SHRD','D200','TPW','PC2','SDBT','POT','OHC','VMX0']))\n",
    "Predictor_Sets.append(('Set2', ['PER','SHRD','D200','TPW','PC2','POT','OHC','VMX0']))\n",
    "Predictor_Sets.append(('Set3', ['PER','SHRD','D200','TPW','SDBT','POT','OHC','VMX0']))\n",
    "Predictor_Sets.append(('Kaplan 2015', ['PER','SHRD','D200','RHLO','PX30','SDBT','POT','OHC']))\n",
    "Predictor_Sets.append(('Kaplan 2015 Imp', ['PER','SHRD','D200','TPW','PC2','SDBT','POT','OHC','VMX0'])) #ICDA didn't exist in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function normalizes the provided data and desired column names\n",
    "\n",
    "def normalization(data,column_names):\n",
    "    data_nur=data[column_names]\n",
    "    data_nur=(data_nur-data_nur.mean())/(data_nur.std()) #standard normal distribution\n",
    "    data[column_names]=data_nur[column_names]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized and Non-Normalized Data Sets\n",
    "\n",
    "Data_Sets=[]\n",
    "\n",
    "num_col=['VMX0','PER','SHRD','D200','RHLO','PX30','SDBT','POT','OHC','TPW','PC2','U200','TPWC','AVBT','RSST']\n",
    "ships_nor=normalization(ships,num_col)\n",
    "\n",
    "\n",
    "# Adding created data set into a series\n",
    "Data_Sets.append(('Normalized', ships_nor))\n",
    "Data_Sets.append(('Not Normalized', ships))\n",
    "\n",
    "# # Data Set 1: Diving Data Sets into Train and Forecast By Year\n",
    "# data_train_by_year = ships[(ships['YEAR']>=year_train[0]) & (ships['YEAR']<=year_train[1])]\n",
    "# data_fcst_by_year = ships[(ships['YEAR']>=year_fcst[0]) & (ships['YEAR']<=year_fcst[1])]\n",
    "\n",
    "# TAR_0 = data_train_by_year[data_train_by_year['TAR']==0]\n",
    "# TAR_1 = data_train_by_year[data_train_by_year['TAR']==1]\n",
    "\n",
    "# TAR_0_count_train,TAR_1_count_train=data_train_by_year['TAR'].value_counts()\n",
    "\n",
    "# # Data Set 2: Undersampling Data Set 1\n",
    "# ### Undersampling RI=0 Rows\n",
    "\n",
    "# TAR_0_under=TAR_0.sample(TAR_1_count_train)\n",
    "# data_train_under = pd.concat([TAR_0_under,TAR_1], axis=0)\n",
    "\n",
    "# # data_train_under['TAR'].value_counts().plot(kind='bar', title='count (target)')\n",
    "\n",
    "# # Data Set 3: Oversampling Data Set 1\n",
    "# ### Undersampling RI=1 Rows\n",
    "\n",
    "# TAR_1_over=TAR_1.sample(TAR_0_count_train,replace=True)\n",
    "# data_train_over = pd.concat([TAR_0,TAR_1_over], axis=0)\n",
    "\n",
    "# # data_train_over['TAR'].value_counts().plot(kind='bar', title='count (target)')\n",
    "# # plt.title('TAR Count After Oversampling')\n",
    "\n",
    "\n",
    "# # Data Set 4: Normalized Data Set 1\n",
    "\n",
    "# num_col=['VMX0','PER','SHRD','D200','RHLO','PX30','SDBT','POT','OHC','TPW','PC2','U200','TPWC','AVBT','RSST']\n",
    "# ships_nor=normalization(ships,num_col)\n",
    "\n",
    "# data_train_nor = ships_nor[(ships_nor['YEAR']>=year_train[0]) & (ships_nor['YEAR']<=year_train[1])]\n",
    "# data_fcst_nor = ships_nor[(ships_nor['YEAR']>=year_fcst[0]) & (ships_nor['YEAR']<=year_fcst[1])]\n",
    "\n",
    "# TAR_0_nor = data_train_nor[data_train_nor['TAR']==0]\n",
    "# TAR_1_nor = data_train_nor[data_train_nor['TAR']==1]\n",
    "\n",
    "# # Data Set 5: Undersampling Data Set 4 (Normalized)\n",
    "\n",
    "# TAR_0_under_nor=TAR_0_nor.sample(TAR_1_count_train)\n",
    "# data_train_under_nor = pd.concat([TAR_0_under_nor,TAR_1_nor], axis=0)\n",
    "\n",
    "# # Data Set 6: Oversampling Data Set 5 (Normalized)\n",
    "\n",
    "# TAR_1_over_nor=TAR_1_nor.sample(TAR_0_count_train,replace=True)\n",
    "# data_train_over_nor = pd.concat([TAR_0_nor,TAR_1_over_nor], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# # Adding created data set into a series\n",
    "# Data_Sets.append(('By Year', data_train_by_year,data_fcst_by_year))\n",
    "# Data_Sets.append(('Undersample', data_train_under,data_fcst_by_year))\n",
    "# Data_Sets.append(('Oversample', data_train_over,data_fcst_by_year))\n",
    "# Data_Sets.append(('Normalized', data_train_nor,data_fcst_nor))\n",
    "# Data_Sets.append(('Undersample (Normalized)', data_train_under_nor,data_fcst_by_year))\n",
    "# Data_Sets.append(('Oversample (Normalized)', data_train_over_nor,data_fcst_by_year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-be794d777225>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Data Set 1: Diving Data Sets into Train and Forecast By Year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mforecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mships\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Data Sets\n",
    "\n",
    "Data_Sets=[]\n",
    "\n",
    "# Data Set 1: Diving Data Sets into Train and Forecast By Year\n",
    "kf = KFold(n_splits=3, random_state=1, shuffle=False)\n",
    "train,forecast = kf.split(ships.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], flip_y=0, random_state=1)\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# # enumerate the splits and summarize the distributions\n",
    "# for train_ix, test_ix in kfold.split(X, y):\n",
    "# \t# select rows\n",
    "# \ttrain_X, test_X = X[train_ix], X[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2857, 2858, 2859, ..., 5711, 5712, 5713]),\n",
       " array([   0,    1,    2, ..., 2854, 2855, 2856]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2, ..., 2854, 2855, 2856]),\n",
       " array([2857, 2858, 2859, ..., 5711, 5712, 5713]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TAR_0 = data_train_by_year[data_train_by_year['TAR']==0]\n",
    "TAR_1 = data_train_by_year[data_train_by_year['TAR']==1]\n",
    "\n",
    "TAR_0_count_train,TAR_1_count_train=data_train_by_year['TAR'].value_counts()\n",
    "\n",
    "# Data Set 2: Undersampling Data Set 1\n",
    "### Undersampling RI=0 Rows\n",
    "\n",
    "TAR_0_under=TAR_0.sample(TAR_1_count_train)\n",
    "data_train_under = pd.concat([TAR_0_under,TAR_1], axis=0)\n",
    "\n",
    "# data_train_under['TAR'].value_counts().plot(kind='bar', title='count (target)')\n",
    "\n",
    "# Data Set 3: Oversampling Data Set 1\n",
    "### Undersampling RI=1 Rows\n",
    "\n",
    "TAR_1_over=TAR_1.sample(TAR_0_count_train,replace=True)\n",
    "data_train_over = pd.concat([TAR_0,TAR_1_over], axis=0)\n",
    "\n",
    "# data_train_over['TAR'].value_counts().plot(kind='bar', title='count (target)')\n",
    "# plt.title('TAR Count After Oversampling')\n",
    "\n",
    "\n",
    "# Data Set 4: Normalized Data Set 1\n",
    "\n",
    "num_col=['VMX0','PER','SHRD','D200','RHLO','PX30','SDBT','POT','OHC','TPW','PC2','U200','TPWC','AVBT','RSST']\n",
    "ships_nor=normalization(ships,num_col)\n",
    "\n",
    "data_train_nor = ships_nor[(ships_nor['YEAR']>=year_train[0]) & (ships_nor['YEAR']<=year_train[1])]\n",
    "data_fcst_nor = ships_nor[(ships_nor['YEAR']>=year_fcst[0]) & (ships_nor['YEAR']<=year_fcst[1])]\n",
    "\n",
    "TAR_0_nor = data_train_nor[data_train_nor['TAR']==0]\n",
    "TAR_1_nor = data_train_nor[data_train_nor['TAR']==1]\n",
    "\n",
    "# Data Set 5: Undersampling Data Set 4 (Normalized)\n",
    "\n",
    "TAR_0_under_nor=TAR_0_nor.sample(TAR_1_count_train)\n",
    "data_train_under_nor = pd.concat([TAR_0_under_nor,TAR_1_nor], axis=0)\n",
    "\n",
    "# Data Set 6: Oversampling Data Set 5 (Normalized)\n",
    "\n",
    "TAR_1_over_nor=TAR_1_nor.sample(TAR_0_count_train,replace=True)\n",
    "data_train_over_nor = pd.concat([TAR_0_nor,TAR_1_over_nor], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Adding created data set into a series\n",
    "Data_Sets.append(('By Year', data_train_by_year,data_fcst_by_year))\n",
    "Data_Sets.append(('Undersample', data_train_under,data_fcst_by_year))\n",
    "Data_Sets.append(('Oversample', data_train_over,data_fcst_by_year))\n",
    "Data_Sets.append(('Normalized', data_train_nor,data_fcst_nor))\n",
    "Data_Sets.append(('Undersample (Normalized)', data_train_under_nor,data_fcst_by_year))\n",
    "Data_Sets.append(('Oversample (Normalized)', data_train_over_nor,data_fcst_by_year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Sets\n",
    "\n",
    "Models = []\n",
    "\n",
    "# Adding different machine learning models into the list\n",
    "Models.append(('Logistic_Regression', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "Models.append(('K_Neighbors_Classifier', KNeighborsClassifier(n_neighbors=15)))\n",
    "Models.append(('Decision_Tree', DecisionTreeClassifier(random_state=1,min_samples_split=10,max_depth=5)))\n",
    "Models.append(('Random_Forest', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=66, max_depth=6, min_samples_leaf=2, class_weight='balanced')))\n",
    "Models.append(('Neural_Network_Logistic', MLPClassifier((10,10), activation='logistic',max_iter=3000)))\n",
    "Models.append(('Neural_Network_ReLU', MLPClassifier((10,10), activation='relu',max_iter=3000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Calculator\n",
    "\n",
    "ML_Calc function takes in predictor,data, and model sets to predict the given target variable of the forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Calc(predictors,data_sets,models,target):\n",
    "   \n",
    "    results=pd.DataFrame()\n",
    "\n",
    "    for name_pred,features in predictors:\n",
    "        for name_data,data_train,data_fcst in data_sets:\n",
    "        # All predictors for training and validating\n",
    "            XData_train = data_train[features]\n",
    "            YData_train = data_train[target]\n",
    "\n",
    "            # All predictors for training and validating\n",
    "            XData_fcst = data_fcst[features]\n",
    "            YData_fcst = data_fcst[target]\n",
    "            # For loop will iterate through each models in 'models' list\n",
    "            \n",
    "            for name_ML, model in models:\n",
    "                model.fit(XData_train,YData_train)\n",
    "                prediction_train=model.predict(XData_train)\n",
    "                prediction_fcst=model.predict(XData_fcst)\n",
    "                \n",
    "                # Performance Metrics\n",
    "                cmatrix_fcst = confusion_matrix(YData_fcst, prediction_fcst)\n",
    "                \n",
    "                false_neg=cmatrix_fcst[1,0]\n",
    "                false_pos=cmatrix_fcst[0,1]\n",
    "                true_pos=cmatrix_fcst[1,1]\n",
    "                true_neg=cmatrix_fcst[0,0]\n",
    "                \n",
    "                pss=((cmatrix_fcst[0,0] * cmatrix_fcst[1,1]) - (cmatrix_fcst[0,1] * cmatrix_fcst[1,0])) * 1.0 / ((cmatrix_fcst[1,1] + cmatrix_fcst[1,0]) * (cmatrix_fcst[0,1] + cmatrix_fcst[0,0]))\n",
    "                far=(cmatrix_fcst[0,1] * 1.0) / (cmatrix_fcst[0,1] + cmatrix_fcst[1,1])\n",
    "                pod=(cmatrix_fcst[1,1] * 1.0) / (cmatrix_fcst[1,0] + cmatrix_fcst[1,1]) \n",
    "                precision=precision_score(YData_fcst, prediction_fcst, average=None)[1]\n",
    "                recall=recall_score(YData_fcst, prediction_fcst)\n",
    "                f1=f1_score(YData_fcst, prediction_fcst)\n",
    "                brier_score=brier_score_loss(YData_fcst,prediction_fcst)\n",
    "                \n",
    "                results=results.append({\"Predictor Set\":name_pred,\"Data Set\":name_data, \n",
    "                                        \"ML Name\":name_ML,\"False Negative\":false_neg,\"False Positive\":false_pos,\n",
    "                                        \"PSS\":pss,\"FAR\":far,\"POD\":pod, \"Recall\":recall,\"Precision\":precision,\"F1\":f1, \n",
    "                                        \"Brier Score\":brier_score}, \n",
    "                                       ignore_index = True) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    results=results[[\"Data Set\",\"Predictor Set\", \"ML Name\",\"False Negative\",\n",
    "                     \"False Positive\",\"PSS\",\"FAR\",\"POD\",\"F1\",\"Precision\",\"Brier Score\"]]\n",
    "    results=results.sort_values('False Negative')\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result=ML_Calc(Predictor_Sets,Data_Sets,Models,'TAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result.sort_values('PSS',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
