{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to build Machine Learning model for hurricane intensity forecast  \n",
    "import pandas as pd # For data manipulation and analysis\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np # For scientific computing\n",
    "\n",
    "#Machine Learning Tools\n",
    "import sklearn # For machine learning library\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#from sklearn.ensemble import ExtraTreesClassifier    # Extra tree classifier\n",
    "from sklearn.metrics import confusion_matrix # Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "from sklearn.metrics import brier_score_loss  # Compute the Brier score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import brier_score_loss  # Compute the Brier score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt  #plotting library\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE #SMOTE oversampling\n",
    "\n",
    "#Displaying More Rows\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>VMX0</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>ID</th>\n",
       "      <th>DELV12</th>\n",
       "      <th>DELV24</th>\n",
       "      <th>DELV36</th>\n",
       "      <th>DELV48</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>OHC</th>\n",
       "      <th>TPW</th>\n",
       "      <th>PC2</th>\n",
       "      <th>U200</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>RSST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980727</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>11.3</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9999</td>\n",
       "      <td>6.3</td>\n",
       "      <td>103</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-101</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-58</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>55.7</td>\n",
       "      <td>-473</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980727</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-27.2</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9999</td>\n",
       "      <td>11.2</td>\n",
       "      <td>118</td>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-102</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>-360</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-29.2</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>116</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-105</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>56.9</td>\n",
       "      <td>-381</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-31.3</td>\n",
       "      <td>1008</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>91</td>\n",
       "      <td>71</td>\n",
       "      <td>57</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-100</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>-44</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>-481</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-33.3</td>\n",
       "      <td>1007</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-89</td>\n",
       "      <td>15</td>\n",
       "      <td>190</td>\n",
       "      <td>-46</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-516</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME    DATE  HOUR  VMX0   LAT   LON  MSLP        ID  DELV12  DELV24  \\\n",
       "0  ALEX  980727    12    25  11.3 -25.4  1009  AL011998       0       5   \n",
       "1  ALEX  980727    18    25  11.7 -27.2  1009  AL011998       0       5   \n",
       "2  ALEX  980728     0    25  12.2 -29.2  1009  AL011998       5      10   \n",
       "3  ALEX  980728     6    25  12.6 -31.3  1008  AL011998       5      10   \n",
       "4  ALEX  980728    12    30  12.9 -33.3  1007  AL011998       5       5   \n",
       "\n",
       "   DELV36  DELV48   PER  SHRD  D200  RHLO  PX30  SDBT  POT  OHC  TPW  PC2  \\\n",
       "0      10      10  9999   6.3   103    68    72  13.8 -101   12    0  -58   \n",
       "1      10      10  9999  11.2   118    69    55  12.6 -102   17    0  -10   \n",
       "2      10      10     0   8.6   116    71    70  12.8 -105   21    0   -3   \n",
       "3      10      15     0  12.2    91    71    57  12.2 -100   29    0  -44   \n",
       "4       5      10     5  10.5    88    71    83  10.1  -89   15  190  -46   \n",
       "\n",
       "   U200  TPWC  AVBT  RSST  \n",
       "0  -7.9  55.7  -473  27.4  \n",
       "1  -6.4  55.7  -360  27.4  \n",
       "2  -8.8  56.9  -381  27.4  \n",
       "3  -6.0  52.7  -481  27.2  \n",
       "4  -6.5  55.3  -516  27.1  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#====================================\n",
    "#Read SHIPS spread-sheet data\n",
    "#====================================\n",
    "# Set up the location of the SHIPS data\n",
    "fname='Dataset_SHIPS_RII_ATL.csv'\n",
    "#fname='Dataset_SHIPS_RII_EPAC.csv'\n",
    "\n",
    "# Read SHIPS data\n",
    "ships = pd.read_csv(fname)\n",
    "ships.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================\n",
    "# Set up parameters\n",
    "#================================\n",
    "# Year range for training and validating\n",
    "year_train=['1998','2008']\n",
    "\n",
    "# Year range for forecast\n",
    "year_fcst=['2009','2017']\n",
    "\n",
    "# Variable name for predictand\n",
    "TargetName='DELV24'\n",
    "\n",
    "# Threshold of Rapid Intensification \n",
    "RIValue=30\n",
    "\n",
    "# Climatology of RI (30 kt) frequency at Atlantic basin (Kaplan et al. 2015)\n",
    "clim=0.125   #ATL 30 kt\n",
    "#clim=0.084   #EPAC 30 kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>VMX0</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>ID</th>\n",
       "      <th>DELV12</th>\n",
       "      <th>DELV24</th>\n",
       "      <th>DELV36</th>\n",
       "      <th>DELV48</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>OHC</th>\n",
       "      <th>TPW</th>\n",
       "      <th>PC2</th>\n",
       "      <th>U200</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>RSST</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-29.2</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>116</td>\n",
       "      <td>71</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-105</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>56.9</td>\n",
       "      <td>-381.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-31.3</td>\n",
       "      <td>1008</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>91</td>\n",
       "      <td>71</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-100</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>-481.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-33.3</td>\n",
       "      <td>1007</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>83.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-89</td>\n",
       "      <td>15.0</td>\n",
       "      <td>190</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>55.3</td>\n",
       "      <td>-516.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980728</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-35.1</td>\n",
       "      <td>1006</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>44</td>\n",
       "      <td>72</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>-86</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>56.6</td>\n",
       "      <td>-270.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>980729</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-36.8</td>\n",
       "      <td>1005</td>\n",
       "      <td>AL011998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>37</td>\n",
       "      <td>74</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-80</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>57.7</td>\n",
       "      <td>-443.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>07</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>OPHE</td>\n",
       "      <td>171013</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-32.5</td>\n",
       "      <td>973</td>\n",
       "      <td>AL172017</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>580</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>-349.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171106</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-50.7</td>\n",
       "      <td>1010</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>14</td>\n",
       "      <td>67</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>864</td>\n",
       "      <td>118.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171106</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>29.1</td>\n",
       "      <td>-50.4</td>\n",
       "      <td>1010</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>-93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>934</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>46.6</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171106</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-50.2</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>-90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>895</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171107</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1008</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>-3</td>\n",
       "      <td>65</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>-81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>938</td>\n",
       "      <td>149.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3743 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NAME    DATE  HOUR  VMX0   LAT   LON  MSLP        ID  DELV12  DELV24  \\\n",
       "2     ALEX  980728     0    25  12.2 -29.2  1009  AL011998     5.0    10.0   \n",
       "3     ALEX  980728     6    25  12.6 -31.3  1008  AL011998     5.0    10.0   \n",
       "4     ALEX  980728    12    30  12.9 -33.3  1007  AL011998     5.0     5.0   \n",
       "5     ALEX  980728    18    30  13.1 -35.1  1006  AL011998     5.0     5.0   \n",
       "6     ALEX  980729     0    35  13.3 -36.8  1005  AL011998     0.0     0.0   \n",
       "...    ...     ...   ...   ...   ...   ...   ...       ...     ...     ...   \n",
       "7379  OPHE  171013    18    80  32.0 -32.5   973  AL172017    15.0    20.0   \n",
       "7393  RINA  171106     6    30  29.0 -50.7  1010  AL192017     0.0    10.0   \n",
       "7394  RINA  171106    12    30  29.1 -50.4  1010  AL192017     5.0    10.0   \n",
       "7395  RINA  171106    18    30  29.4 -50.2  1009  AL192017    10.0    10.0   \n",
       "7396  RINA  171107     0    35  30.0 -50.0  1008  AL192017     5.0    10.0   \n",
       "\n",
       "      DELV36  DELV48   PER  SHRD  D200  RHLO  PX30  SDBT  POT   OHC  TPW  \\\n",
       "2       10.0    10.0   0.0   8.6   116    71  70.0  12.8 -105  21.0    0   \n",
       "3       10.0    15.0   0.0  12.2    91    71  57.0  12.2 -100  29.0    0   \n",
       "4        5.0    10.0   5.0  10.5    88    71  83.0  10.1  -89  15.0  190   \n",
       "5       10.0    15.0   5.0   9.7    44    72  35.0  15.9  -86  22.0   15   \n",
       "6        5.0    10.0   5.0   9.9    37    74  56.0  14.5  -80  24.0    0   \n",
       "...      ...     ...   ...   ...   ...   ...   ...   ...  ...   ...  ...   \n",
       "7379    10.0     0.0 -10.0   9.7     5    62  45.0  12.2  -24   0.0  580   \n",
       "7393    10.0    20.0   0.0  14.8    14    67  33.0  29.4  -94   1.0  864   \n",
       "7394    15.0    15.0   0.0  14.3     5    66  28.0  26.2  -93   0.0  934   \n",
       "7395    20.0    15.0   0.0  18.8     3    65  27.0  24.5  -90   0.0  895   \n",
       "7396    10.0    10.0   5.0  21.4    -3    65  26.0  22.7  -81   0.0  938   \n",
       "\n",
       "        PC2  U200  TPWC   AVBT  RSST MONTH  YEAR  TAR  \n",
       "2      -3.0  -8.8  56.9 -381.0  27.4    07  1998    0  \n",
       "3     -44.0  -6.0  52.7 -481.0  27.2    07  1998    0  \n",
       "4     -46.0  -6.5  55.3 -516.0  27.1    07  1998    0  \n",
       "5      36.0  -7.2  56.6 -270.0  27.1    07  1998    0  \n",
       "6      -6.0 -10.3  57.7 -443.0  27.1    07  1998    0  \n",
       "...     ...   ...   ...    ...   ...   ...   ...  ...  \n",
       "7379   24.0  24.0  52.5 -349.0  26.0    10  2017    0  \n",
       "7393  118.0  18.0  45.7 -159.0  26.2    11  2017    0  \n",
       "7394  126.0  16.2  46.6 -106.0  26.1    11  2017    0  \n",
       "7395  138.0  18.0  46.0  -57.0  25.9    11  2017    0  \n",
       "7396  149.0  20.0  46.0  -24.0  25.6    11  2017    0  \n",
       "\n",
       "[3743 rows x 29 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#================================\n",
    "# Data pre-processing\n",
    "#================================\n",
    "# Set all 9999s as NaNs\n",
    "ships = ships.replace(9999,np.NaN)\n",
    "\n",
    "# drop NaNs\n",
    "ships=ships.dropna()\n",
    "\n",
    "# Pad the date columns with 00 for the year 2000\n",
    "ships['DATE'] = ships['DATE'].apply(lambda x: str(x).zfill(6))\n",
    "\n",
    "# Extract month from date\n",
    "ships['MONTH'] = ships['DATE'].apply(lambda x: str(x)[2:4])\n",
    "\n",
    "# Extract year from date\n",
    "ships['YEAR'] = ships['DATE'].apply(lambda x: ('19' + str(x)[0:2]) if (str(x)[0:1]!= '0' and str(x)[0:1]!= '1') else ('20' + str(x)[0:2]))\n",
    "ships.head()\n",
    "\n",
    "# Set the target column\n",
    "ships['TAR'] = ships[TargetName].apply(lambda x: 1 if x >= RIValue else 0)\n",
    "ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variable names for predictors\n",
    "Predictor_Sets=[]\n",
    "\n",
    "# Adding different machine learning models into the list\n",
    "Predictor_Sets.append(('Set1', ['PER','SHRD','D200','TPW','PC2','SDBT','POT','OHC','VMX0']))\n",
    "Predictor_Sets.append(('Set2', ['PER','SHRD','D200','TPW','PC2','POT','OHC','VMX0']))\n",
    "Predictor_Sets.append(('Set3', ['PER','SHRD','D200','TPW','SDBT','POT','OHC','VMX0']))\n",
    "Predictor_Sets.append(('Kaplan 2015', ['PER','SHRD','D200','RHLO','PX30','SDBT','POT','OHC']))\n",
    "Predictor_Sets.append(('Kaplan 2015 Imp', ['PER','SHRD','D200','TPW','PC2','SDBT','POT','OHC','VMX0'])) #ICDA didn't exist in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Data_Sets=[]\n",
    "\n",
    "# Data Set 1: Sampling All\n",
    "### Dividing Data into two by year\n",
    "data_train_by_year = ships[(ships['YEAR']>=year_train[0]) & (ships['YEAR']<=year_train[1])]\n",
    "data_fcst_by_year = ships[(ships['YEAR']>=year_fcst[0]) & (ships['YEAR']<=year_fcst[1])]\n",
    "\n",
    "TAR_0 = data_train_by_year[data_train_by_year['TAR']==0]\n",
    "TAR_1 = data_train_by_year[data_train_by_year['TAR']==1]\n",
    "\n",
    "TAR_0_count_train,TAR_1_count_train=data_train_by_year['TAR'].value_counts()\n",
    "\n",
    "# Data Set 2: Under-Sampling\n",
    "### Undersampling RI=0 Rows\n",
    "\n",
    "TAR_0_under=TAR_0.sample(TAR_1_count_train)\n",
    "data_train_under = pd.concat([TAR_0_under,TAR_1], axis=0)\n",
    "\n",
    "data_train_under['TAR'].value_counts().plot(kind='bar', title='count (target)')\n",
    "\n",
    "# Data Set 3: Over-Sampling\n",
    "### Undersampling RI=1 Rows\n",
    "\n",
    "TAR_1_over=TAR_1.sample(TAR_0_count_train,replace=True)\n",
    "data_train_over = pd.concat([TAR_0,TAR_1_over], axis=0)\n",
    "\n",
    "data_train_over['TAR'].value_counts().plot(kind='bar', title='count (target)')\n",
    "plt.title('TAR Count After Oversampling')\n",
    "\n",
    "\n",
    "# Data Set 4: Normalized\n",
    "\n",
    "def normalization(data,column_names):\n",
    "    data_nur=data[column_names]\n",
    "    data_nur=(data_nur-data_nur.mean())/(data_nur.std()) #standard normal distribution\n",
    "    data[column_names]=data_nur[column_names]\n",
    "    return data\n",
    "\n",
    "### Applying function above to numerical features\n",
    "num_col=['VMX0','PER','SHRD','D200','RHLO','PX30','SDBT','POT','OHC','TPW','PC2','U200','TPWC','AVBT','RSST']\n",
    "ships_nor=normalization(ships,num_col)\n",
    "\n",
    "data_train_nor = ships_nor[(ships_nor['YEAR']>=year_train[0]) & (ships_nor['YEAR']<=year_train[1])]\n",
    "data_fcst_nor = ships_nor[(ships_nor['YEAR']>=year_fcst[0]) & (ships_nor['YEAR']<=year_fcst[1])]\n",
    "\n",
    "\n",
    "TAR_0_nor = data_train_nor[data_train_nor['TAR']==0]\n",
    "TAR_1_nor = data_train_nor[data_train_nor['TAR']==1]\n",
    "\n",
    "# Data Set 5: Under-Sampling (Normalized)\n",
    "### Undersampling RI=0 Rows\n",
    "\n",
    "TAR_0_under_nor=TAR_0_nor.sample(TAR_1_count_train)\n",
    "data_train_under_nor = pd.concat([TAR_0_under_nor,TAR_1_nor], axis=0)\n",
    "\n",
    "# Data Set 6: Over-Sampling (Normalized)\n",
    "### Undersampling RI=1 Rows\n",
    "\n",
    "TAR_1_over_nor=TAR_1_nor.sample(TAR_0_count_train,replace=True)\n",
    "data_train_over_nor = pd.concat([TAR_0_nor,TAR_1_over_nor], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Adding newly created data into a series\n",
    "Data_Sets.append(('By Year', data_train_by_year,data_fcst_by_year))\n",
    "Data_Sets.append(('Undersample', data_train_under,data_fcst_by_year))\n",
    "Data_Sets.append(('Oversample', data_train_over,data_fcst_by_year))\n",
    "Data_Sets.append(('Normalized', data_train_nor,data_fcst_nor))\n",
    "Data_Sets.append(('Undersample (Normalized)', data_train_under_nor,data_fcst_by_year))\n",
    "Data_Sets.append(('Oversample (Normalized)', data_train_over_nor,data_fcst_by_year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>VMX0</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>ID</th>\n",
       "      <th>DELV12</th>\n",
       "      <th>DELV24</th>\n",
       "      <th>DELV36</th>\n",
       "      <th>DELV48</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>OHC</th>\n",
       "      <th>TPW</th>\n",
       "      <th>PC2</th>\n",
       "      <th>U200</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>RSST</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <td>BILL</td>\n",
       "      <td>090815</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.032871</td>\n",
       "      <td>11.2</td>\n",
       "      <td>-34.5</td>\n",
       "      <td>1004</td>\n",
       "      <td>AL032009</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.127474</td>\n",
       "      <td>-0.367757</td>\n",
       "      <td>-1.978362</td>\n",
       "      <td>1.313188</td>\n",
       "      <td>-0.557732</td>\n",
       "      <td>0.054042</td>\n",
       "      <td>-0.739833</td>\n",
       "      <td>-0.648851</td>\n",
       "      <td>-0.626043</td>\n",
       "      <td>0.160641</td>\n",
       "      <td>-1.984346</td>\n",
       "      <td>0.524722</td>\n",
       "      <td>0.425423</td>\n",
       "      <td>-0.198957</td>\n",
       "      <td>08</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>BILL</td>\n",
       "      <td>090816</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.032871</td>\n",
       "      <td>11.2</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>1004</td>\n",
       "      <td>AL032009</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.127474</td>\n",
       "      <td>-0.561105</td>\n",
       "      <td>-1.359290</td>\n",
       "      <td>1.313188</td>\n",
       "      <td>-0.631034</td>\n",
       "      <td>0.313634</td>\n",
       "      <td>-0.739833</td>\n",
       "      <td>-0.845529</td>\n",
       "      <td>-0.626043</td>\n",
       "      <td>-0.241931</td>\n",
       "      <td>-1.874345</td>\n",
       "      <td>0.454018</td>\n",
       "      <td>-0.152894</td>\n",
       "      <td>-0.269324</td>\n",
       "      <td>08</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>BILL</td>\n",
       "      <td>090816</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.856830</td>\n",
       "      <td>11.5</td>\n",
       "      <td>-36.5</td>\n",
       "      <td>1002</td>\n",
       "      <td>AL032009</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.127474</td>\n",
       "      <td>-0.799947</td>\n",
       "      <td>-0.482270</td>\n",
       "      <td>1.173271</td>\n",
       "      <td>0.541791</td>\n",
       "      <td>0.529961</td>\n",
       "      <td>-0.588660</td>\n",
       "      <td>-0.779970</td>\n",
       "      <td>-0.626043</td>\n",
       "      <td>-0.753308</td>\n",
       "      <td>-1.595109</td>\n",
       "      <td>0.524722</td>\n",
       "      <td>-0.627410</td>\n",
       "      <td>-0.269324</td>\n",
       "      <td>08</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>BILL</td>\n",
       "      <td>090816</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.504748</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-37.8</td>\n",
       "      <td>997</td>\n",
       "      <td>AL032009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.149174</td>\n",
       "      <td>-1.345871</td>\n",
       "      <td>-0.301708</td>\n",
       "      <td>1.033355</td>\n",
       "      <td>0.395188</td>\n",
       "      <td>0.270369</td>\n",
       "      <td>-0.346782</td>\n",
       "      <td>-0.517732</td>\n",
       "      <td>-0.626043</td>\n",
       "      <td>-0.448658</td>\n",
       "      <td>-1.408953</td>\n",
       "      <td>0.567144</td>\n",
       "      <td>-0.113351</td>\n",
       "      <td>-0.269324</td>\n",
       "      <td>08</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>BILL</td>\n",
       "      <td>090816</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.328707</td>\n",
       "      <td>12.6</td>\n",
       "      <td>-39.4</td>\n",
       "      <td>994</td>\n",
       "      <td>AL032009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.149174</td>\n",
       "      <td>-1.129776</td>\n",
       "      <td>0.472133</td>\n",
       "      <td>1.173271</td>\n",
       "      <td>1.164854</td>\n",
       "      <td>-0.854530</td>\n",
       "      <td>-0.044435</td>\n",
       "      <td>-0.517732</td>\n",
       "      <td>-0.626043</td>\n",
       "      <td>-0.992675</td>\n",
       "      <td>-1.146641</td>\n",
       "      <td>0.736833</td>\n",
       "      <td>-0.810297</td>\n",
       "      <td>-0.339692</td>\n",
       "      <td>08</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>OPHE</td>\n",
       "      <td>171013</td>\n",
       "      <td>18</td>\n",
       "      <td>0.551498</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-32.5</td>\n",
       "      <td>973</td>\n",
       "      <td>AL172017</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.405076</td>\n",
       "      <td>-0.504238</td>\n",
       "      <td>-0.714422</td>\n",
       "      <td>-0.925474</td>\n",
       "      <td>-0.667685</td>\n",
       "      <td>-0.508407</td>\n",
       "      <td>1.316126</td>\n",
       "      <td>-1.238886</td>\n",
       "      <td>1.337704</td>\n",
       "      <td>0.465291</td>\n",
       "      <td>1.696480</td>\n",
       "      <td>-0.960054</td>\n",
       "      <td>0.282080</td>\n",
       "      <td>-1.535935</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171106</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.208912</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-50.7</td>\n",
       "      <td>1010</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.383376</td>\n",
       "      <td>0.075807</td>\n",
       "      <td>-0.482270</td>\n",
       "      <td>-0.225892</td>\n",
       "      <td>-1.107494</td>\n",
       "      <td>1.972138</td>\n",
       "      <td>-0.800303</td>\n",
       "      <td>-1.206106</td>\n",
       "      <td>2.299263</td>\n",
       "      <td>1.488043</td>\n",
       "      <td>1.188780</td>\n",
       "      <td>-1.921624</td>\n",
       "      <td>1.221227</td>\n",
       "      <td>-1.395201</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171106</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.208912</td>\n",
       "      <td>29.1</td>\n",
       "      <td>-50.4</td>\n",
       "      <td>1010</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.383376</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>-0.714422</td>\n",
       "      <td>-0.365809</td>\n",
       "      <td>-1.290748</td>\n",
       "      <td>1.510641</td>\n",
       "      <td>-0.770068</td>\n",
       "      <td>-1.238886</td>\n",
       "      <td>2.536266</td>\n",
       "      <td>1.575086</td>\n",
       "      <td>1.036470</td>\n",
       "      <td>-1.794357</td>\n",
       "      <td>1.483200</td>\n",
       "      <td>-1.465568</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171106</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.208912</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-50.2</td>\n",
       "      <td>1009</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.383376</td>\n",
       "      <td>0.530743</td>\n",
       "      <td>-0.766012</td>\n",
       "      <td>-0.505725</td>\n",
       "      <td>-1.327399</td>\n",
       "      <td>1.265471</td>\n",
       "      <td>-0.679364</td>\n",
       "      <td>-1.238886</td>\n",
       "      <td>2.404221</td>\n",
       "      <td>1.705650</td>\n",
       "      <td>1.188780</td>\n",
       "      <td>-1.879201</td>\n",
       "      <td>1.725401</td>\n",
       "      <td>-1.606303</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>RINA</td>\n",
       "      <td>171107</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.032871</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1008</td>\n",
       "      <td>AL192017</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.127474</td>\n",
       "      <td>0.826452</td>\n",
       "      <td>-0.920780</td>\n",
       "      <td>-0.505725</td>\n",
       "      <td>-1.364049</td>\n",
       "      <td>1.005879</td>\n",
       "      <td>-0.407252</td>\n",
       "      <td>-1.238886</td>\n",
       "      <td>2.549809</td>\n",
       "      <td>1.825334</td>\n",
       "      <td>1.358013</td>\n",
       "      <td>-1.879201</td>\n",
       "      <td>1.888516</td>\n",
       "      <td>-1.817404</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1464 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NAME    DATE  HOUR      VMX0   LAT   LON  MSLP        ID  DELV12  \\\n",
       "4489  BILL  090815    18 -1.032871  11.2 -34.5  1004  AL032009     5.0   \n",
       "4490  BILL  090816     0 -1.032871  11.2 -35.5  1004  AL032009    15.0   \n",
       "4491  BILL  090816     6 -0.856830  11.5 -36.5  1002  AL032009    15.0   \n",
       "4492  BILL  090816    12 -0.504748  12.0 -37.8   997  AL032009    10.0   \n",
       "4493  BILL  090816    18 -0.328707  12.6 -39.4   994  AL032009    10.0   \n",
       "...    ...     ...   ...       ...   ...   ...   ...       ...     ...   \n",
       "7379  OPHE  171013    18  0.551498  32.0 -32.5   973  AL172017    15.0   \n",
       "7393  RINA  171106     6 -1.208912  29.0 -50.7  1010  AL192017     0.0   \n",
       "7394  RINA  171106    12 -1.208912  29.1 -50.4  1010  AL192017     5.0   \n",
       "7395  RINA  171106    18 -1.208912  29.4 -50.2  1009  AL192017    10.0   \n",
       "7396  RINA  171107     0 -1.032871  30.0 -50.0  1008  AL192017     5.0   \n",
       "\n",
       "      DELV24  DELV36  DELV48       PER      SHRD      D200      RHLO  \\\n",
       "4489    20.0    30.0    45.0  0.127474 -0.367757 -1.978362  1.313188   \n",
       "4490    25.0    40.0    50.0  0.127474 -0.561105 -1.359290  1.313188   \n",
       "4491    25.0    40.0    50.0  0.127474 -0.799947 -0.482270  1.173271   \n",
       "4492    25.0    35.0    45.0  1.149174 -1.345871 -0.301708  1.033355   \n",
       "4493    25.0    35.0    45.0  1.149174 -1.129776  0.472133  1.173271   \n",
       "...      ...     ...     ...       ...       ...       ...       ...   \n",
       "7379    20.0    10.0     0.0 -1.405076 -0.504238 -0.714422 -0.925474   \n",
       "7393    10.0    10.0    20.0 -0.383376  0.075807 -0.482270 -0.225892   \n",
       "7394    10.0    15.0    15.0 -0.383376  0.018939 -0.714422 -0.365809   \n",
       "7395    10.0    20.0    15.0 -0.383376  0.530743 -0.766012 -0.505725   \n",
       "7396    10.0    10.0    10.0  0.127474  0.826452 -0.920780 -0.505725   \n",
       "\n",
       "          PX30      SDBT       POT       OHC       TPW       PC2      U200  \\\n",
       "4489 -0.557732  0.054042 -0.739833 -0.648851 -0.626043  0.160641 -1.984346   \n",
       "4490 -0.631034  0.313634 -0.739833 -0.845529 -0.626043 -0.241931 -1.874345   \n",
       "4491  0.541791  0.529961 -0.588660 -0.779970 -0.626043 -0.753308 -1.595109   \n",
       "4492  0.395188  0.270369 -0.346782 -0.517732 -0.626043 -0.448658 -1.408953   \n",
       "4493  1.164854 -0.854530 -0.044435 -0.517732 -0.626043 -0.992675 -1.146641   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7379 -0.667685 -0.508407  1.316126 -1.238886  1.337704  0.465291  1.696480   \n",
       "7393 -1.107494  1.972138 -0.800303 -1.206106  2.299263  1.488043  1.188780   \n",
       "7394 -1.290748  1.510641 -0.770068 -1.238886  2.536266  1.575086  1.036470   \n",
       "7395 -1.327399  1.265471 -0.679364 -1.238886  2.404221  1.705650  1.188780   \n",
       "7396 -1.364049  1.005879 -0.407252 -1.238886  2.549809  1.825334  1.358013   \n",
       "\n",
       "          TPWC      AVBT      RSST MONTH  YEAR  TAR  \n",
       "4489  0.524722  0.425423 -0.198957    08  2009    0  \n",
       "4490  0.454018 -0.152894 -0.269324    08  2009    0  \n",
       "4491  0.524722 -0.627410 -0.269324    08  2009    0  \n",
       "4492  0.567144 -0.113351 -0.269324    08  2009    0  \n",
       "4493  0.736833 -0.810297 -0.339692    08  2009    0  \n",
       "...        ...       ...       ...   ...   ...  ...  \n",
       "7379 -0.960054  0.282080 -1.535935    10  2017    0  \n",
       "7393 -1.921624  1.221227 -1.395201    11  2017    0  \n",
       "7394 -1.794357  1.483200 -1.465568    11  2017    0  \n",
       "7395 -1.879201  1.725401 -1.606303    11  2017    0  \n",
       "7396 -1.879201  1.888516 -1.817404    11  2017    0  \n",
       "\n",
       "[1464 rows x 29 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fcst_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list\n",
    "Models = []\n",
    "\n",
    "# Adding different machine learning models into the list\n",
    "Models.append(('Logistic_Regression', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "Models.append(('K_Neighbors_Classifier', KNeighborsClassifier(n_neighbors=15)))\n",
    "Models.append(('Decision_Tree', DecisionTreeClassifier(random_state=1,min_samples_split=10,max_depth=5)))\n",
    "Models.append(('Random_Forest', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=66, max_depth=6, min_samples_leaf=2, class_weight='balanced')))\n",
    "Models.append(('Neural_Network_Logistic', MLPClassifier((10,10), activation='logistic',max_iter=3000)))\n",
    "Models.append(('Neural_Network_ReLU', MLPClassifier((10,10), activation='relu',max_iter=3000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Calc(predictors,data_sets,models,target):\n",
    "   \n",
    "    results=pd.DataFrame()\n",
    "\n",
    "    for name_pred,features in predictors:\n",
    "        for name_data,data_train,data_fcst in data_sets:\n",
    "        # All predictors for training and validating\n",
    "            XData_train = data_train[features]\n",
    "            YData_train = data_train[target]\n",
    "\n",
    "            # All predictors for training and validating\n",
    "            XData_fcst = data_fcst[features]\n",
    "            YData_fcst = data_fcst[target]\n",
    "            # For loop will iterate through each models in 'models' list\n",
    "            for name_ML, model in models:\n",
    "                model.fit(XData_train,YData_train)\n",
    "                prediction_train=model.predict(XData_train)\n",
    "                prediction_fcst=model.predict(XData_fcst)\n",
    "                \n",
    "                #P erformance Metrics\n",
    "                cmatrix_fcst = confusion_matrix(YData_fcst, prediction_fcst)\n",
    "                \n",
    "                false_neg=cmatrix_fcst[1,0]\n",
    "                false_pos=cmatrix_fcst[0,1]\n",
    "                true_pos=cmatrix_fcst[1,1]\n",
    "                true_neg=cmatrix_fcst[0,0]\n",
    "                \n",
    "                pss=((cmatrix_fcst[0,0] * cmatrix_fcst[1,1]) - (cmatrix_fcst[0,1] * cmatrix_fcst[1,0])) * 1.0 / ((cmatrix_fcst[1,1] + cmatrix_fcst[1,0]) * (cmatrix_fcst[0,1] + cmatrix_fcst[0,0]))\n",
    "                far=(cmatrix_fcst[0,1] * 1.0) / (cmatrix_fcst[0,1] + cmatrix_fcst[1,1])\n",
    "                pod=(cmatrix_fcst[1,1] * 1.0) / (cmatrix_fcst[1,0] + cmatrix_fcst[1,1]) \n",
    "                precision=precision_score(YData_fcst, prediction_fcst, average=None)[1]\n",
    "                recall=recall_score(YData_fcst, prediction_fcst)\n",
    "                f1=f1_score(YData_fcst, prediction_fcst)\n",
    "                brier_score=brier_score_loss(YData_fcst,prediction_fcst)\n",
    "                \n",
    "                results=results.append({\"Predictor Set\":name_pred,\"Data Set\":name_data, \n",
    "                                        \"ML Name\":name_ML,\"False Negative\":false_neg,\"False Positive\":false_pos,\n",
    "                                        \"PSS\":pss,\"FAR\":far,\"POD\":pod, \"Recall\":recall,\"Precision\":precision,\"F1\":f1, \n",
    "                                        \"Brier Score\":brier_score}, \n",
    "                                       ignore_index = True) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    results=results[[\"Data Set\",\"Predictor Set\", \"ML Name\",\"False Negative\",\n",
    "                     \"False Positive\",\"PSS\",\"FAR\",\"POD\",\"F1\",\"Precision\",\"Brier Score\"]]\n",
    "    results=results.sort_values('False Negative')\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\kwonk\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Result=ML_Calc(Predictor_Sets,Data_Sets,Models,'TAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Predictor Set</th>\n",
       "      <th>ML Name</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>PSS</th>\n",
       "      <th>FAR</th>\n",
       "      <th>POD</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Brier Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>38.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.427676</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.307167</td>\n",
       "      <td>0.196507</td>\n",
       "      <td>0.277322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>30.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.425056</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.287812</td>\n",
       "      <td>0.177215</td>\n",
       "      <td>0.331284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>33.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>0.421080</td>\n",
       "      <td>0.818702</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.291411</td>\n",
       "      <td>0.181298</td>\n",
       "      <td>0.315574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>39.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>0.408636</td>\n",
       "      <td>0.811441</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>0.188559</td>\n",
       "      <td>0.288251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>38.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>0.398484</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.181087</td>\n",
       "      <td>0.303962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>40.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.389596</td>\n",
       "      <td>0.818930</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.286645</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.299180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>38.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>0.383514</td>\n",
       "      <td>0.825919</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.174081</td>\n",
       "      <td>0.317623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>36.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>0.376684</td>\n",
       "      <td>0.832423</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.271787</td>\n",
       "      <td>0.167577</td>\n",
       "      <td>0.336749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>44.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.376310</td>\n",
       "      <td>0.816594</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.286689</td>\n",
       "      <td>0.183406</td>\n",
       "      <td>0.285519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>49.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.373924</td>\n",
       "      <td>0.804455</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.296992</td>\n",
       "      <td>0.195545</td>\n",
       "      <td>0.255464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>45.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.370743</td>\n",
       "      <td>0.817181</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>0.285223</td>\n",
       "      <td>0.182819</td>\n",
       "      <td>0.284153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>38.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>0.368544</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.270677</td>\n",
       "      <td>0.167598</td>\n",
       "      <td>0.331284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>43.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.367655</td>\n",
       "      <td>0.823285</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.279146</td>\n",
       "      <td>0.176715</td>\n",
       "      <td>0.299863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>45.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0.367000</td>\n",
       "      <td>0.819172</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>0.282794</td>\n",
       "      <td>0.180828</td>\n",
       "      <td>0.287568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>43.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>0.366907</td>\n",
       "      <td>0.823651</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.176349</td>\n",
       "      <td>0.300546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>43.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>0.366907</td>\n",
       "      <td>0.823651</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.176349</td>\n",
       "      <td>0.300546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>39.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.365971</td>\n",
       "      <td>0.831758</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.270928</td>\n",
       "      <td>0.168242</td>\n",
       "      <td>0.327186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>36.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0.363211</td>\n",
       "      <td>0.837743</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.264748</td>\n",
       "      <td>0.162257</td>\n",
       "      <td>0.349044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>46.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>0.356942</td>\n",
       "      <td>0.822126</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.278438</td>\n",
       "      <td>0.177874</td>\n",
       "      <td>0.290301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>46.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>0.356942</td>\n",
       "      <td>0.822126</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.278438</td>\n",
       "      <td>0.177874</td>\n",
       "      <td>0.290301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>55.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.356241</td>\n",
       "      <td>0.796657</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.299795</td>\n",
       "      <td>0.203343</td>\n",
       "      <td>0.232923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>44.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.355352</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.273616</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.304645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>43.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>0.345949</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.266458</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.319672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>60.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.344124</td>\n",
       "      <td>0.786164</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.304933</td>\n",
       "      <td>0.213836</td>\n",
       "      <td>0.211749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>60.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.344124</td>\n",
       "      <td>0.786164</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.304933</td>\n",
       "      <td>0.213836</td>\n",
       "      <td>0.211749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>52.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.343001</td>\n",
       "      <td>0.815085</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.282004</td>\n",
       "      <td>0.184915</td>\n",
       "      <td>0.264344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>58.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.342534</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.297240</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.226093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>48.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.340569</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.292350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>48.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.340569</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.292350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>53.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.338183</td>\n",
       "      <td>0.815271</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.184729</td>\n",
       "      <td>0.262295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>41.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>0.337622</td>\n",
       "      <td>0.840074</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.159926</td>\n",
       "      <td>0.340164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>49.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.334253</td>\n",
       "      <td>0.827133</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.270085</td>\n",
       "      <td>0.172867</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>45.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.334066</td>\n",
       "      <td>0.834990</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>0.263074</td>\n",
       "      <td>0.165010</td>\n",
       "      <td>0.317623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>54.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0.333365</td>\n",
       "      <td>0.815461</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.279773</td>\n",
       "      <td>0.184539</td>\n",
       "      <td>0.260246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>54.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0.333365</td>\n",
       "      <td>0.815461</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.279773</td>\n",
       "      <td>0.184539</td>\n",
       "      <td>0.260246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>56.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0.331213</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.282908</td>\n",
       "      <td>0.188976</td>\n",
       "      <td>0.249317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>58.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.329809</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.286885</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.237705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>58.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.329809</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.286885</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.237705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>58.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.329061</td>\n",
       "      <td>0.806094</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.286299</td>\n",
       "      <td>0.193906</td>\n",
       "      <td>0.238388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>58.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.329061</td>\n",
       "      <td>0.806094</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.286299</td>\n",
       "      <td>0.193906</td>\n",
       "      <td>0.238388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>64.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.327844</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.303318</td>\n",
       "      <td>0.217687</td>\n",
       "      <td>0.200820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>64.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.327844</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.303318</td>\n",
       "      <td>0.217687</td>\n",
       "      <td>0.200820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>49.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0.327517</td>\n",
       "      <td>0.830472</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.265993</td>\n",
       "      <td>0.169528</td>\n",
       "      <td>0.297814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>49.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0.327517</td>\n",
       "      <td>0.830472</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.265993</td>\n",
       "      <td>0.169528</td>\n",
       "      <td>0.297814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>50.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.327189</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.267581</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>58.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0.326067</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.283976</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.241120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>58.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0.326067</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.283976</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.241120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>54.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.324382</td>\n",
       "      <td>0.820823</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.273567</td>\n",
       "      <td>0.179177</td>\n",
       "      <td>0.268443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>37.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.246279</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.380464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>37.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.246279</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.380464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>55.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0.321061</td>\n",
       "      <td>0.820197</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.273408</td>\n",
       "      <td>0.179803</td>\n",
       "      <td>0.265027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>38.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.313903</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.381148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>52.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>0.310067</td>\n",
       "      <td>0.832967</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.260720</td>\n",
       "      <td>0.167033</td>\n",
       "      <td>0.294399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>42.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.307354</td>\n",
       "      <td>0.849913</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.245364</td>\n",
       "      <td>0.150087</td>\n",
       "      <td>0.361339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>56.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.301272</td>\n",
       "      <td>0.828979</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.171021</td>\n",
       "      <td>0.276639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>41.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.294957</td>\n",
       "      <td>0.855241</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.238683</td>\n",
       "      <td>0.144759</td>\n",
       "      <td>0.379098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>50.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>0.294255</td>\n",
       "      <td>0.843687</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.248804</td>\n",
       "      <td>0.156313</td>\n",
       "      <td>0.321721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>39.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.291121</td>\n",
       "      <td>0.858506</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.235139</td>\n",
       "      <td>0.141494</td>\n",
       "      <td>0.395492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>46.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>0.286583</td>\n",
       "      <td>0.852252</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.240117</td>\n",
       "      <td>0.147748</td>\n",
       "      <td>0.354508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>46.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>0.286583</td>\n",
       "      <td>0.852252</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.240117</td>\n",
       "      <td>0.147748</td>\n",
       "      <td>0.354508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>60.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.830846</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.256604</td>\n",
       "      <td>0.169154</td>\n",
       "      <td>0.269126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set1</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>32.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>0.280689</td>\n",
       "      <td>0.867220</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.225617</td>\n",
       "      <td>0.132780</td>\n",
       "      <td>0.450137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>32.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>0.280689</td>\n",
       "      <td>0.867220</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.225617</td>\n",
       "      <td>0.132780</td>\n",
       "      <td>0.450137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>55.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0.280642</td>\n",
       "      <td>0.841304</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.248299</td>\n",
       "      <td>0.158696</td>\n",
       "      <td>0.301913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>47.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>0.269789</td>\n",
       "      <td>0.856890</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>0.233429</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>0.363388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Oversample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>58.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.264689</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.243478</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.297131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>34.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.264315</td>\n",
       "      <td>0.869806</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.221176</td>\n",
       "      <td>0.130194</td>\n",
       "      <td>0.452186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>34.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.259076</td>\n",
       "      <td>0.871056</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.219370</td>\n",
       "      <td>0.128944</td>\n",
       "      <td>0.456967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>31.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.253321</td>\n",
       "      <td>0.874189</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.215795</td>\n",
       "      <td>0.125811</td>\n",
       "      <td>0.481557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>31.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.253321</td>\n",
       "      <td>0.874189</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.215795</td>\n",
       "      <td>0.125811</td>\n",
       "      <td>0.481557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>44.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.252058</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.398907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>44.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.252058</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.398907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>47.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>0.864322</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>0.223448</td>\n",
       "      <td>0.135678</td>\n",
       "      <td>0.384563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>46.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.244667</td>\n",
       "      <td>0.865794</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.221922</td>\n",
       "      <td>0.134206</td>\n",
       "      <td>0.392760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>57.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>0.238819</td>\n",
       "      <td>0.855984</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.228663</td>\n",
       "      <td>0.144016</td>\n",
       "      <td>0.327186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>57.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>0.238819</td>\n",
       "      <td>0.855984</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.228663</td>\n",
       "      <td>0.144016</td>\n",
       "      <td>0.327186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>53.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.237884</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.224551</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.353825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>59.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>0.231428</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.226974</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.321038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>54.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>0.228574</td>\n",
       "      <td>0.863216</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.221226</td>\n",
       "      <td>0.136784</td>\n",
       "      <td>0.355874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>49.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.226469</td>\n",
       "      <td>0.868552</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.216735</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>0.390027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>34.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>0.220902</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.207048</td>\n",
       "      <td>0.120513</td>\n",
       "      <td>0.491803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>26.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0.220528</td>\n",
       "      <td>0.883028</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.116972</td>\n",
       "      <td>0.543716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Undersample</td>\n",
       "      <td>Set3</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>31.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>0.218142</td>\n",
       "      <td>0.881418</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.205074</td>\n",
       "      <td>0.118582</td>\n",
       "      <td>0.513661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>43.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>0.211218</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.207824</td>\n",
       "      <td>0.123188</td>\n",
       "      <td>0.442623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>41.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>0.197652</td>\n",
       "      <td>0.880985</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.202561</td>\n",
       "      <td>0.119015</td>\n",
       "      <td>0.467896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>61.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.193348</td>\n",
       "      <td>0.868110</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>0.210692</td>\n",
       "      <td>0.131890</td>\n",
       "      <td>0.342896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>71.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.177348</td>\n",
       "      <td>0.862651</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.209945</td>\n",
       "      <td>0.137349</td>\n",
       "      <td>0.293033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>89.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>0.815166</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.230088</td>\n",
       "      <td>0.184834</td>\n",
       "      <td>0.178279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>101.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.174261</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.102459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>101.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.174261</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.102459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>101.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.174261</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.102459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>101.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.174261</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.102459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>49.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.173325</td>\n",
       "      <td>0.882440</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.117560</td>\n",
       "      <td>0.438525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>49.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.173325</td>\n",
       "      <td>0.882440</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.117560</td>\n",
       "      <td>0.438525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>101.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.168273</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.254717</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.107923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>82.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.160273</td>\n",
       "      <td>0.852564</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.147436</td>\n",
       "      <td>0.237705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>58.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>0.159150</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.195531</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.393443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>35.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.890973</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.189602</td>\n",
       "      <td>0.109027</td>\n",
       "      <td>0.543033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>35.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.890973</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.189602</td>\n",
       "      <td>0.109027</td>\n",
       "      <td>0.543033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>35.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.890973</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.189602</td>\n",
       "      <td>0.109027</td>\n",
       "      <td>0.543033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>42.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>0.157653</td>\n",
       "      <td>0.888745</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.190899</td>\n",
       "      <td>0.111255</td>\n",
       "      <td>0.497951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>69.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>0.156297</td>\n",
       "      <td>0.873391</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.198653</td>\n",
       "      <td>0.126609</td>\n",
       "      <td>0.325137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>34.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.142309</td>\n",
       "      <td>0.893785</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.185587</td>\n",
       "      <td>0.106215</td>\n",
       "      <td>0.563525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>34.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.142309</td>\n",
       "      <td>0.893785</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.185587</td>\n",
       "      <td>0.106215</td>\n",
       "      <td>0.563525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>34.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.142309</td>\n",
       "      <td>0.893785</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.185587</td>\n",
       "      <td>0.106215</td>\n",
       "      <td>0.563525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>106.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.129210</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.212560</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.111339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>107.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.119152</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.200957</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.114071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>107.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.119152</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.200957</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.114071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>110.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.100206</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.112022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set3</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>113.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.096229</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.096311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>70.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>0.095341</td>\n",
       "      <td>0.891791</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>0.108209</td>\n",
       "      <td>0.374317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>114.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.086920</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set1</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>114.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.086920</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>114.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.086920</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>77.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>0.084815</td>\n",
       "      <td>0.891489</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>0.170569</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.338798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>114.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.083177</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.158192</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.101776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>112.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.116120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>117.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.071716</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.092896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set2</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>117.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.067973</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.134969</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.096311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>115.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.067131</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.139037</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.109973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>118.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.048185</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.107923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>121.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.038969</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.096995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>121.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.038220</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.089172</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.097678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>122.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.079470</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.094945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>0.909509</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.164804</td>\n",
       "      <td>0.090491</td>\n",
       "      <td>0.816940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>122.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.079470</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.094945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>123.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.094945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>123.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.094945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>0.020958</td>\n",
       "      <td>0.910864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163683</td>\n",
       "      <td>0.089136</td>\n",
       "      <td>0.893443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>124.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.094945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>125.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>125.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.015204</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.092896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>125.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.014455</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.041958</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.093579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>124.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.101776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>124.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.101776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>125.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.095628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>125.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.096311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set3</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>126.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.092213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set1</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>126.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.094262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>126.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.094262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.912050</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.161578</td>\n",
       "      <td>0.087950</td>\n",
       "      <td>0.900273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>123.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.056497</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.114071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.912209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161412</td>\n",
       "      <td>0.087791</td>\n",
       "      <td>0.908470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.096995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.096995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.912389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161108</td>\n",
       "      <td>0.087611</td>\n",
       "      <td>0.910519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>127.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.092213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>127.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.092213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set2</td>\n",
       "      <td>K_Neighbors_Classifier</td>\n",
       "      <td>127.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.093579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By Year</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Normalized</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Set1</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.912568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160804</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.912568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set2</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Kaplan 2015 Imp</td>\n",
       "      <td>Neural_Network_Logistic</td>\n",
       "      <td>122.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.001778</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.127732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Oversample (Normalized)</td>\n",
       "      <td>Set3</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.002246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Neural_Network_ReLU</td>\n",
       "      <td>121.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-0.106989</td>\n",
       "      <td>0.968610</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>0.230191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Undersample (Normalized)</td>\n",
       "      <td>Kaplan 2015</td>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>115.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>-0.393946</td>\n",
       "      <td>0.980741</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.032379</td>\n",
       "      <td>0.019259</td>\n",
       "      <td>0.530738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Data Set    Predictor Set                  ML Name  \\\n",
       "84                 Oversample             Set3      Logistic_Regression   \n",
       "47                Undersample             Set2      Neural_Network_ReLU   \n",
       "82                Undersample             Set3  Neural_Network_Logistic   \n",
       "78                Undersample             Set3      Logistic_Regression   \n",
       "114               Undersample      Kaplan 2015      Logistic_Regression   \n",
       "42                Undersample             Set2      Logistic_Regression   \n",
       "154               Undersample  Kaplan 2015 Imp  Neural_Network_Logistic   \n",
       "83                Undersample             Set3      Neural_Network_ReLU   \n",
       "120                Oversample      Kaplan 2015      Logistic_Regression   \n",
       "117               Undersample      Kaplan 2015            Random_Forest   \n",
       "81                Undersample             Set3            Random_Forest   \n",
       "89                 Oversample             Set3      Neural_Network_ReLU   \n",
       "48                 Oversample             Set2      Logistic_Regression   \n",
       "119               Undersample      Kaplan 2015      Neural_Network_ReLU   \n",
       "153               Undersample  Kaplan 2015 Imp            Random_Forest   \n",
       "9                 Undersample             Set1            Random_Forest   \n",
       "118               Undersample      Kaplan 2015  Neural_Network_Logistic   \n",
       "155               Undersample  Kaplan 2015 Imp      Neural_Network_ReLU   \n",
       "6                 Undersample             Set1      Logistic_Regression   \n",
       "150               Undersample  Kaplan 2015 Imp      Logistic_Regression   \n",
       "87                 Oversample             Set3            Random_Forest   \n",
       "45                Undersample             Set2            Random_Forest   \n",
       "10                Undersample             Set1  Neural_Network_Logistic   \n",
       "93                 Normalized             Set3            Random_Forest   \n",
       "75                    By Year             Set3            Random_Forest   \n",
       "50                 Oversample             Set2            Decision_Tree   \n",
       "123                Oversample      Kaplan 2015            Random_Forest   \n",
       "12                 Oversample             Set1      Logistic_Regression   \n",
       "156                Oversample  Kaplan 2015 Imp      Logistic_Regression   \n",
       "124                Oversample      Kaplan 2015  Neural_Network_Logistic   \n",
       "46                Undersample             Set2  Neural_Network_Logistic   \n",
       "53                 Oversample             Set2      Neural_Network_ReLU   \n",
       "11                Undersample             Set1      Neural_Network_ReLU   \n",
       "159                Oversample  Kaplan 2015 Imp            Random_Forest   \n",
       "15                 Oversample             Set1            Random_Forest   \n",
       "88                 Oversample             Set3  Neural_Network_Logistic   \n",
       "3                     By Year             Set1            Random_Forest   \n",
       "147                   By Year  Kaplan 2015 Imp            Random_Forest   \n",
       "165                Normalized  Kaplan 2015 Imp            Random_Forest   \n",
       "21                 Normalized             Set1            Random_Forest   \n",
       "111                   By Year      Kaplan 2015            Random_Forest   \n",
       "129                Normalized      Kaplan 2015            Random_Forest   \n",
       "14                 Oversample             Set1            Decision_Tree   \n",
       "158                Oversample  Kaplan 2015 Imp            Decision_Tree   \n",
       "160                Oversample  Kaplan 2015 Imp  Neural_Network_Logistic   \n",
       "57                 Normalized             Set2            Random_Forest   \n",
       "39                    By Year             Set2            Random_Forest   \n",
       "17                 Oversample             Set1      Neural_Network_ReLU   \n",
       "13                 Oversample             Set1   K_Neighbors_Classifier   \n",
       "157                Oversample  Kaplan 2015 Imp   K_Neighbors_Classifier   \n",
       "51                 Oversample             Set2            Random_Forest   \n",
       "49                 Oversample             Set2   K_Neighbors_Classifier   \n",
       "16                 Oversample             Set1  Neural_Network_Logistic   \n",
       "121                Oversample      Kaplan 2015   K_Neighbors_Classifier   \n",
       "161                Oversample  Kaplan 2015 Imp      Neural_Network_ReLU   \n",
       "85                 Oversample             Set3   K_Neighbors_Classifier   \n",
       "80                Undersample             Set3            Decision_Tree   \n",
       "115               Undersample      Kaplan 2015   K_Neighbors_Classifier   \n",
       "8                 Undersample             Set1            Decision_Tree   \n",
       "152               Undersample  Kaplan 2015 Imp            Decision_Tree   \n",
       "125                Oversample      Kaplan 2015      Neural_Network_ReLU   \n",
       "7                 Undersample             Set1   K_Neighbors_Classifier   \n",
       "151               Undersample  Kaplan 2015 Imp   K_Neighbors_Classifier   \n",
       "86                 Oversample             Set3            Decision_Tree   \n",
       "122                Oversample      Kaplan 2015            Decision_Tree   \n",
       "52                 Oversample             Set2  Neural_Network_Logistic   \n",
       "43                Undersample             Set2   K_Neighbors_Classifier   \n",
       "64   Undersample (Normalized)             Set2  Neural_Network_Logistic   \n",
       "168  Undersample (Normalized)  Kaplan 2015 Imp      Logistic_Regression   \n",
       "24   Undersample (Normalized)             Set1      Logistic_Regression   \n",
       "30    Oversample (Normalized)             Set1      Logistic_Regression   \n",
       "174   Oversample (Normalized)  Kaplan 2015 Imp      Logistic_Regression   \n",
       "172  Undersample (Normalized)  Kaplan 2015 Imp  Neural_Network_Logistic   \n",
       "44                Undersample             Set2            Decision_Tree   \n",
       "31    Oversample (Normalized)             Set1   K_Neighbors_Classifier   \n",
       "175   Oversample (Normalized)  Kaplan 2015 Imp   K_Neighbors_Classifier   \n",
       "67    Oversample (Normalized)             Set2   K_Neighbors_Classifier   \n",
       "100  Undersample (Normalized)             Set3  Neural_Network_Logistic   \n",
       "116               Undersample      Kaplan 2015            Decision_Tree   \n",
       "28   Undersample (Normalized)             Set1  Neural_Network_Logistic   \n",
       "66    Oversample (Normalized)             Set2      Logistic_Regression   \n",
       "60   Undersample (Normalized)             Set2      Logistic_Regression   \n",
       "79                Undersample             Set3   K_Neighbors_Classifier   \n",
       "96   Undersample (Normalized)             Set3      Logistic_Regression   \n",
       "61   Undersample (Normalized)             Set2   K_Neighbors_Classifier   \n",
       "102   Oversample (Normalized)             Set3      Logistic_Regression   \n",
       "106   Oversample (Normalized)             Set3  Neural_Network_Logistic   \n",
       "143   Oversample (Normalized)      Kaplan 2015      Neural_Network_ReLU   \n",
       "2                     By Year             Set1            Decision_Tree   \n",
       "20                 Normalized             Set1            Decision_Tree   \n",
       "164                Normalized  Kaplan 2015 Imp            Decision_Tree   \n",
       "146                   By Year  Kaplan 2015 Imp            Decision_Tree   \n",
       "169  Undersample (Normalized)  Kaplan 2015 Imp   K_Neighbors_Classifier   \n",
       "25   Undersample (Normalized)             Set1   K_Neighbors_Classifier   \n",
       "95                 Normalized             Set3      Neural_Network_ReLU   \n",
       "103   Oversample (Normalized)             Set3   K_Neighbors_Classifier   \n",
       "97   Undersample (Normalized)             Set3   K_Neighbors_Classifier   \n",
       "32    Oversample (Normalized)             Set1            Decision_Tree   \n",
       "68    Oversample (Normalized)             Set2            Decision_Tree   \n",
       "176   Oversample (Normalized)  Kaplan 2015 Imp            Decision_Tree   \n",
       "65   Undersample (Normalized)             Set2      Neural_Network_ReLU   \n",
       "101  Undersample (Normalized)             Set3      Neural_Network_ReLU   \n",
       "62   Undersample (Normalized)             Set2            Decision_Tree   \n",
       "26   Undersample (Normalized)             Set1            Decision_Tree   \n",
       "170  Undersample (Normalized)  Kaplan 2015 Imp            Decision_Tree   \n",
       "23                 Normalized             Set1      Neural_Network_ReLU   \n",
       "74                    By Year             Set3            Decision_Tree   \n",
       "92                 Normalized             Set3            Decision_Tree   \n",
       "76                    By Year             Set3  Neural_Network_Logistic   \n",
       "91                 Normalized             Set3   K_Neighbors_Classifier   \n",
       "173  Undersample (Normalized)  Kaplan 2015 Imp      Neural_Network_ReLU   \n",
       "163                Normalized  Kaplan 2015 Imp   K_Neighbors_Classifier   \n",
       "19                 Normalized             Set1   K_Neighbors_Classifier   \n",
       "113                   By Year      Kaplan 2015      Neural_Network_ReLU   \n",
       "34    Oversample (Normalized)             Set1  Neural_Network_Logistic   \n",
       "59                 Normalized             Set2      Neural_Network_ReLU   \n",
       "149                   By Year  Kaplan 2015 Imp      Neural_Network_ReLU   \n",
       "127                Normalized      Kaplan 2015   K_Neighbors_Classifier   \n",
       "55                 Normalized             Set2   K_Neighbors_Classifier   \n",
       "167                Normalized  Kaplan 2015 Imp      Neural_Network_ReLU   \n",
       "131                Normalized      Kaplan 2015      Neural_Network_ReLU   \n",
       "126                Normalized      Kaplan 2015      Logistic_Regression   \n",
       "108                   By Year      Kaplan 2015      Logistic_Regression   \n",
       "144                   By Year  Kaplan 2015 Imp      Logistic_Regression   \n",
       "142   Oversample (Normalized)      Kaplan 2015  Neural_Network_Logistic   \n",
       "0                     By Year             Set1      Logistic_Regression   \n",
       "18                 Normalized             Set1      Logistic_Regression   \n",
       "162                Normalized  Kaplan 2015 Imp      Logistic_Regression   \n",
       "139   Oversample (Normalized)      Kaplan 2015   K_Neighbors_Classifier   \n",
       "109                   By Year      Kaplan 2015   K_Neighbors_Classifier   \n",
       "5                     By Year             Set1      Neural_Network_ReLU   \n",
       "36                    By Year             Set2      Logistic_Regression   \n",
       "54                 Normalized             Set2      Logistic_Regression   \n",
       "110                   By Year      Kaplan 2015            Decision_Tree   \n",
       "128                Normalized      Kaplan 2015            Decision_Tree   \n",
       "90                 Normalized             Set3      Logistic_Regression   \n",
       "72                    By Year             Set3      Logistic_Regression   \n",
       "73                    By Year             Set3   K_Neighbors_Classifier   \n",
       "1                     By Year             Set1   K_Neighbors_Classifier   \n",
       "145                   By Year  Kaplan 2015 Imp   K_Neighbors_Classifier   \n",
       "133  Undersample (Normalized)      Kaplan 2015   K_Neighbors_Classifier   \n",
       "70    Oversample (Normalized)             Set2  Neural_Network_Logistic   \n",
       "132  Undersample (Normalized)      Kaplan 2015      Logistic_Regression   \n",
       "56                 Normalized             Set2            Decision_Tree   \n",
       "38                    By Year             Set2            Decision_Tree   \n",
       "136  Undersample (Normalized)      Kaplan 2015  Neural_Network_Logistic   \n",
       "41                    By Year             Set2      Neural_Network_ReLU   \n",
       "35    Oversample (Normalized)             Set1      Neural_Network_ReLU   \n",
       "37                    By Year             Set2   K_Neighbors_Classifier   \n",
       "112                   By Year      Kaplan 2015  Neural_Network_Logistic   \n",
       "94                 Normalized             Set3  Neural_Network_Logistic   \n",
       "105   Oversample (Normalized)             Set3            Random_Forest   \n",
       "140   Oversample (Normalized)      Kaplan 2015            Decision_Tree   \n",
       "141   Oversample (Normalized)      Kaplan 2015            Random_Forest   \n",
       "99   Undersample (Normalized)             Set3            Random_Forest   \n",
       "98   Undersample (Normalized)             Set3            Decision_Tree   \n",
       "77                    By Year             Set3      Neural_Network_ReLU   \n",
       "148                   By Year  Kaplan 2015 Imp  Neural_Network_Logistic   \n",
       "135  Undersample (Normalized)      Kaplan 2015            Random_Forest   \n",
       "69    Oversample (Normalized)             Set2            Random_Forest   \n",
       "130                Normalized      Kaplan 2015  Neural_Network_Logistic   \n",
       "40                    By Year             Set2  Neural_Network_Logistic   \n",
       "107   Oversample (Normalized)             Set3      Neural_Network_ReLU   \n",
       "179   Oversample (Normalized)  Kaplan 2015 Imp      Neural_Network_ReLU   \n",
       "58                 Normalized             Set2  Neural_Network_Logistic   \n",
       "63   Undersample (Normalized)             Set2            Random_Forest   \n",
       "33    Oversample (Normalized)             Set1            Random_Forest   \n",
       "166                Normalized  Kaplan 2015 Imp  Neural_Network_Logistic   \n",
       "177   Oversample (Normalized)  Kaplan 2015 Imp            Random_Forest   \n",
       "4                     By Year             Set1  Neural_Network_Logistic   \n",
       "22                 Normalized             Set1  Neural_Network_Logistic   \n",
       "171  Undersample (Normalized)  Kaplan 2015 Imp            Random_Forest   \n",
       "27   Undersample (Normalized)             Set1            Random_Forest   \n",
       "29   Undersample (Normalized)             Set1      Neural_Network_ReLU   \n",
       "138   Oversample (Normalized)      Kaplan 2015      Logistic_Regression   \n",
       "71    Oversample (Normalized)             Set2      Neural_Network_ReLU   \n",
       "178   Oversample (Normalized)  Kaplan 2015 Imp  Neural_Network_Logistic   \n",
       "104   Oversample (Normalized)             Set3            Decision_Tree   \n",
       "137  Undersample (Normalized)      Kaplan 2015      Neural_Network_ReLU   \n",
       "134  Undersample (Normalized)      Kaplan 2015            Decision_Tree   \n",
       "\n",
       "     False Negative  False Positive       PSS       FAR       POD        F1  \\\n",
       "84             38.0           368.0  0.427676  0.803493  0.703125  0.307167   \n",
       "47             30.0           455.0  0.425056  0.822785  0.765625  0.287812   \n",
       "82             33.0           429.0  0.421080  0.818702  0.742188  0.291411   \n",
       "78             39.0           383.0  0.408636  0.811441  0.695312  0.296667   \n",
       "114            38.0           407.0  0.398484  0.818913  0.703125  0.288000   \n",
       "42             40.0           398.0  0.389596  0.818930  0.687500  0.286645   \n",
       "154            38.0           427.0  0.383514  0.825919  0.703125  0.279070   \n",
       "83             36.0           457.0  0.376684  0.832423  0.718750  0.271787   \n",
       "120            44.0           374.0  0.376310  0.816594  0.656250  0.286689   \n",
       "117            49.0           325.0  0.373924  0.804455  0.617188  0.296992   \n",
       "81             45.0           371.0  0.370743  0.817181  0.648438  0.285223   \n",
       "89             38.0           447.0  0.368544  0.832402  0.703125  0.270677   \n",
       "48             43.0           396.0  0.367655  0.823285  0.664062  0.279146   \n",
       "119            45.0           376.0  0.367000  0.819172  0.648438  0.282794   \n",
       "153            43.0           397.0  0.366907  0.823651  0.664062  0.278689   \n",
       "9              43.0           397.0  0.366907  0.823651  0.664062  0.278689   \n",
       "118            39.0           440.0  0.365971  0.831758  0.695312  0.270928   \n",
       "155            36.0           475.0  0.363211  0.837743  0.718750  0.264748   \n",
       "6              46.0           379.0  0.356942  0.822126  0.640625  0.278438   \n",
       "150            46.0           379.0  0.356942  0.822126  0.640625  0.278438   \n",
       "87             55.0           286.0  0.356241  0.796657  0.570312  0.299795   \n",
       "45             44.0           402.0  0.355352  0.827160  0.656250  0.273616   \n",
       "10             43.0           425.0  0.345949  0.833333  0.664062  0.266458   \n",
       "93             60.0           250.0  0.344124  0.786164  0.531250  0.304933   \n",
       "75             60.0           250.0  0.344124  0.786164  0.531250  0.304933   \n",
       "50             52.0           335.0  0.343001  0.815085  0.593750  0.282004   \n",
       "123            58.0           273.0  0.342534  0.795918  0.546875  0.297240   \n",
       "12             48.0           380.0  0.340569  0.826087  0.625000  0.272109   \n",
       "156            48.0           380.0  0.340569  0.826087  0.625000  0.272109   \n",
       "124            53.0           331.0  0.338183  0.815271  0.585938  0.280899   \n",
       "46             41.0           457.0  0.337622  0.840074  0.679688  0.258929   \n",
       "53             49.0           378.0  0.334253  0.827133  0.617188  0.270085   \n",
       "11             45.0           420.0  0.334066  0.834990  0.648438  0.263074   \n",
       "159            54.0           327.0  0.333365  0.815461  0.578125  0.279773   \n",
       "15             54.0           327.0  0.333365  0.815461  0.578125  0.279773   \n",
       "88             56.0           309.0  0.331213  0.811024  0.562500  0.282908   \n",
       "3              58.0           290.0  0.329809  0.805556  0.546875  0.286885   \n",
       "147            58.0           290.0  0.329809  0.805556  0.546875  0.286885   \n",
       "165            58.0           291.0  0.329061  0.806094  0.546875  0.286299   \n",
       "21             58.0           291.0  0.329061  0.806094  0.546875  0.286299   \n",
       "111            64.0           230.0  0.327844  0.782313  0.500000  0.303318   \n",
       "129            64.0           230.0  0.327844  0.782313  0.500000  0.303318   \n",
       "14             49.0           387.0  0.327517  0.830472  0.617188  0.265993   \n",
       "158            49.0           387.0  0.327517  0.830472  0.617188  0.265993   \n",
       "160            50.0           377.0  0.327189  0.828571  0.609375  0.267581   \n",
       "57             58.0           295.0  0.326067  0.808219  0.546875  0.283976   \n",
       "39             58.0           295.0  0.326067  0.808219  0.546875  0.283976   \n",
       "17             54.0           339.0  0.324382  0.820823  0.578125  0.273567   \n",
       "13             37.0           520.0  0.321716  0.851064  0.710938  0.246279   \n",
       "157            37.0           520.0  0.321716  0.851064  0.710938  0.246279   \n",
       "51             55.0           333.0  0.321061  0.820197  0.570312  0.273408   \n",
       "49             38.0           520.0  0.313903  0.852459  0.703125  0.243902   \n",
       "16             52.0           379.0  0.310067  0.832967  0.593750  0.260720   \n",
       "121            42.0           487.0  0.307354  0.849913  0.671875  0.245364   \n",
       "161            56.0           349.0  0.301272  0.828979  0.562500  0.262295   \n",
       "85             41.0           514.0  0.294957  0.855241  0.679688  0.238683   \n",
       "80             50.0           421.0  0.294255  0.843687  0.609375  0.248804   \n",
       "115            39.0           540.0  0.291121  0.858506  0.695312  0.235139   \n",
       "8              46.0           473.0  0.286583  0.852252  0.640625  0.240117   \n",
       "152            46.0           473.0  0.286583  0.852252  0.640625  0.240117   \n",
       "125            60.0           334.0  0.281250  0.830846  0.531250  0.256604   \n",
       "7              32.0           627.0  0.280689  0.867220  0.750000  0.225617   \n",
       "151            32.0           627.0  0.280689  0.867220  0.750000  0.225617   \n",
       "86             55.0           387.0  0.280642  0.841304  0.570312  0.248299   \n",
       "122            47.0           485.0  0.269789  0.856890  0.632812  0.233429   \n",
       "52             58.0           377.0  0.264689  0.843400  0.546875  0.243478   \n",
       "43             34.0           628.0  0.264315  0.869806  0.734375  0.221176   \n",
       "64             34.0           635.0  0.259076  0.871056  0.734375  0.219370   \n",
       "168            31.0           674.0  0.253321  0.874189  0.757812  0.215795   \n",
       "24             31.0           674.0  0.253321  0.874189  0.757812  0.215795   \n",
       "30             44.0           540.0  0.252058  0.865385  0.656250  0.223404   \n",
       "174            44.0           540.0  0.252058  0.865385  0.656250  0.223404   \n",
       "172            47.0           516.0  0.246585  0.864322  0.632812  0.223448   \n",
       "44             46.0           529.0  0.244667  0.865794  0.640625  0.221922   \n",
       "31             57.0           422.0  0.238819  0.855984  0.554688  0.228663   \n",
       "175            57.0           422.0  0.238819  0.855984  0.554688  0.228663   \n",
       "67             53.0           465.0  0.237884  0.861111  0.585938  0.224551   \n",
       "100            59.0           411.0  0.231428  0.856250  0.539062  0.226974   \n",
       "116            54.0           467.0  0.228574  0.863216  0.578125  0.221226   \n",
       "28             49.0           522.0  0.226469  0.868552  0.617188  0.216735   \n",
       "66             34.0           686.0  0.220902  0.879487  0.734375  0.207048   \n",
       "60             26.0           770.0  0.220528  0.883028  0.796875  0.204000   \n",
       "79             31.0           721.0  0.218142  0.881418  0.757812  0.205074   \n",
       "96             43.0           605.0  0.211218  0.876812  0.664062  0.207824   \n",
       "61             41.0           644.0  0.197652  0.880985  0.679688  0.202561   \n",
       "102            61.0           441.0  0.193348  0.868110  0.523438  0.210692   \n",
       "106            71.0           358.0  0.177348  0.862651  0.445312  0.209945   \n",
       "143            89.0           172.0  0.175945  0.815166  0.304688  0.230088   \n",
       "2             101.0            49.0  0.174261  0.644737  0.210938  0.264706   \n",
       "20            101.0            49.0  0.174261  0.644737  0.210938  0.264706   \n",
       "164           101.0            49.0  0.174261  0.644737  0.210938  0.264706   \n",
       "146           101.0            49.0  0.174261  0.644737  0.210938  0.264706   \n",
       "169            49.0           593.0  0.173325  0.882440  0.617188  0.197500   \n",
       "25             49.0           593.0  0.173325  0.882440  0.617188  0.197500   \n",
       "95            101.0            57.0  0.168273  0.678571  0.210938  0.254717   \n",
       "103            82.0           266.0  0.160273  0.852564  0.359375  0.209091   \n",
       "97             58.0           518.0  0.159150  0.880952  0.546875  0.195531   \n",
       "32             35.0           760.0  0.157700  0.890973  0.726562  0.189602   \n",
       "68             35.0           760.0  0.157700  0.890973  0.726562  0.189602   \n",
       "176            35.0           760.0  0.157700  0.890973  0.726562  0.189602   \n",
       "65             42.0           687.0  0.157653  0.888745  0.671875  0.190899   \n",
       "101            69.0           407.0  0.156297  0.873391  0.460938  0.198653   \n",
       "62             34.0           791.0  0.142309  0.893785  0.734375  0.185587   \n",
       "26             34.0           791.0  0.142309  0.893785  0.734375  0.185587   \n",
       "170            34.0           791.0  0.142309  0.893785  0.734375  0.185587   \n",
       "23            106.0            57.0  0.129210  0.721519  0.171875  0.212560   \n",
       "74            107.0            60.0  0.119152  0.740741  0.164062  0.200957   \n",
       "92            107.0            60.0  0.119152  0.740741  0.164062  0.200957   \n",
       "76            110.0            54.0  0.100206  0.750000  0.140625  0.180000   \n",
       "91            113.0            28.0  0.096229  0.651163  0.117188  0.175439   \n",
       "173            70.0           478.0  0.095341  0.891791  0.453125  0.174699   \n",
       "163           114.0            30.0  0.086920  0.681818  0.109375  0.162791   \n",
       "19            114.0            30.0  0.086920  0.681818  0.109375  0.162791   \n",
       "113           114.0            30.0  0.086920  0.681818  0.109375  0.162791   \n",
       "34             77.0           419.0  0.084815  0.891489  0.398438  0.170569   \n",
       "59            114.0            35.0  0.083177  0.714286  0.109375  0.158192   \n",
       "149           112.0            58.0  0.081587  0.783784  0.125000  0.158416   \n",
       "127           117.0            19.0  0.071716  0.633333  0.085938  0.139241   \n",
       "55            117.0            24.0  0.067973  0.685714  0.085938  0.134969   \n",
       "167           115.0            46.0  0.067131  0.779661  0.101562  0.139037   \n",
       "131           118.0            40.0  0.048185  0.800000  0.078125  0.112360   \n",
       "126           121.0            21.0  0.038969  0.750000  0.054688  0.089744   \n",
       "108           121.0            22.0  0.038220  0.758621  0.054688  0.089172   \n",
       "144           122.0            17.0  0.034150  0.739130  0.046875  0.079470   \n",
       "142            10.0          1186.0  0.034150  0.909509  0.921875  0.164804   \n",
       "0             122.0            17.0  0.034150  0.739130  0.046875  0.079470   \n",
       "18            123.0            16.0  0.027086  0.761905  0.039062  0.067114   \n",
       "162           123.0            16.0  0.027086  0.761905  0.039062  0.067114   \n",
       "139             0.0          1308.0  0.020958  0.910864  1.000000  0.163683   \n",
       "109           124.0            15.0  0.020022  0.789474  0.031250  0.054422   \n",
       "5             125.0             9.0  0.016701  0.750000  0.023438  0.042857   \n",
       "36            125.0            11.0  0.015204  0.785714  0.023438  0.042254   \n",
       "54            125.0            12.0  0.014455  0.800000  0.023438  0.041958   \n",
       "110           124.0            25.0  0.012537  0.862069  0.031250  0.050955   \n",
       "128           124.0            25.0  0.012537  0.862069  0.031250  0.050955   \n",
       "90            125.0            15.0  0.012210  0.833333  0.023438  0.041096   \n",
       "72            125.0            16.0  0.011461  0.842105  0.023438  0.040816   \n",
       "73            126.0             9.0  0.008888  0.818182  0.015625  0.028777   \n",
       "1             126.0            12.0  0.006643  0.857143  0.015625  0.028169   \n",
       "145           126.0            12.0  0.006643  0.857143  0.015625  0.028169   \n",
       "133             1.0          1317.0  0.006409  0.912050  0.992188  0.161578   \n",
       "70            123.0            44.0  0.006128  0.897959  0.039062  0.056497   \n",
       "132             0.0          1330.0  0.004491  0.912209  1.000000  0.161412   \n",
       "56            126.0            16.0  0.003649  0.888889  0.015625  0.027397   \n",
       "38            126.0            16.0  0.003649  0.888889  0.015625  0.027397   \n",
       "136             0.0          1333.0  0.002246  0.912389  1.000000  0.161108   \n",
       "41            127.0             8.0  0.001824  0.888889  0.007812  0.014599   \n",
       "35            127.0             8.0  0.001824  0.888889  0.007812  0.014599   \n",
       "37            127.0            10.0  0.000327  0.909091  0.007812  0.014388   \n",
       "112           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "94            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "105           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "140           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "141           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "99            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "98            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "77            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "148           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "135           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "69            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "130           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "40            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "107           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "179           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "58            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "63            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "33            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "166           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "177           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "4             128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "22            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "171           128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "27            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "29            128.0             0.0  0.000000       NaN  0.000000  0.000000   \n",
       "138             0.0          1336.0  0.000000  0.912568  1.000000  0.160804   \n",
       "71            128.0             1.0 -0.000749  1.000000  0.000000  0.000000   \n",
       "178           122.0            65.0 -0.001778  0.915493  0.046875  0.060302   \n",
       "104           128.0             3.0 -0.002246  1.000000  0.000000  0.000000   \n",
       "137           121.0           216.0 -0.106989  0.968610  0.054688  0.039886   \n",
       "134           115.0           662.0 -0.393946  0.980741  0.101562  0.032379   \n",
       "\n",
       "     Precision  Brier Score  \n",
       "84    0.196507     0.277322  \n",
       "47    0.177215     0.331284  \n",
       "82    0.181298     0.315574  \n",
       "78    0.188559     0.288251  \n",
       "114   0.181087     0.303962  \n",
       "42    0.181070     0.299180  \n",
       "154   0.174081     0.317623  \n",
       "83    0.167577     0.336749  \n",
       "120   0.183406     0.285519  \n",
       "117   0.195545     0.255464  \n",
       "81    0.182819     0.284153  \n",
       "89    0.167598     0.331284  \n",
       "48    0.176715     0.299863  \n",
       "119   0.180828     0.287568  \n",
       "153   0.176349     0.300546  \n",
       "9     0.176349     0.300546  \n",
       "118   0.168242     0.327186  \n",
       "155   0.162257     0.349044  \n",
       "6     0.177874     0.290301  \n",
       "150   0.177874     0.290301  \n",
       "87    0.203343     0.232923  \n",
       "45    0.172840     0.304645  \n",
       "10    0.166667     0.319672  \n",
       "93    0.213836     0.211749  \n",
       "75    0.213836     0.211749  \n",
       "50    0.184915     0.264344  \n",
       "123   0.204082     0.226093  \n",
       "12    0.173913     0.292350  \n",
       "156   0.173913     0.292350  \n",
       "124   0.184729     0.262295  \n",
       "46    0.159926     0.340164  \n",
       "53    0.172867     0.291667  \n",
       "11    0.165010     0.317623  \n",
       "159   0.184539     0.260246  \n",
       "15    0.184539     0.260246  \n",
       "88    0.188976     0.249317  \n",
       "3     0.194444     0.237705  \n",
       "147   0.194444     0.237705  \n",
       "165   0.193906     0.238388  \n",
       "21    0.193906     0.238388  \n",
       "111   0.217687     0.200820  \n",
       "129   0.217687     0.200820  \n",
       "14    0.169528     0.297814  \n",
       "158   0.169528     0.297814  \n",
       "160   0.171429     0.291667  \n",
       "57    0.191781     0.241120  \n",
       "39    0.191781     0.241120  \n",
       "17    0.179177     0.268443  \n",
       "13    0.148936     0.380464  \n",
       "157   0.148936     0.380464  \n",
       "51    0.179803     0.265027  \n",
       "49    0.147541     0.381148  \n",
       "16    0.167033     0.294399  \n",
       "121   0.150087     0.361339  \n",
       "161   0.171021     0.276639  \n",
       "85    0.144759     0.379098  \n",
       "80    0.156313     0.321721  \n",
       "115   0.141494     0.395492  \n",
       "8     0.147748     0.354508  \n",
       "152   0.147748     0.354508  \n",
       "125   0.169154     0.269126  \n",
       "7     0.132780     0.450137  \n",
       "151   0.132780     0.450137  \n",
       "86    0.158696     0.301913  \n",
       "122   0.143110     0.363388  \n",
       "52    0.156600     0.297131  \n",
       "43    0.130194     0.452186  \n",
       "64    0.128944     0.456967  \n",
       "168   0.125811     0.481557  \n",
       "24    0.125811     0.481557  \n",
       "30    0.134615     0.398907  \n",
       "174   0.134615     0.398907  \n",
       "172   0.135678     0.384563  \n",
       "44    0.134206     0.392760  \n",
       "31    0.144016     0.327186  \n",
       "175   0.144016     0.327186  \n",
       "67    0.138889     0.353825  \n",
       "100   0.143750     0.321038  \n",
       "116   0.136784     0.355874  \n",
       "28    0.131448     0.390027  \n",
       "66    0.120513     0.491803  \n",
       "60    0.116972     0.543716  \n",
       "79    0.118582     0.513661  \n",
       "96    0.123188     0.442623  \n",
       "61    0.119015     0.467896  \n",
       "102   0.131890     0.342896  \n",
       "106   0.137349     0.293033  \n",
       "143   0.184834     0.178279  \n",
       "2     0.355263     0.102459  \n",
       "20    0.355263     0.102459  \n",
       "164   0.355263     0.102459  \n",
       "146   0.355263     0.102459  \n",
       "169   0.117560     0.438525  \n",
       "25    0.117560     0.438525  \n",
       "95    0.321429     0.107923  \n",
       "103   0.147436     0.237705  \n",
       "97    0.119048     0.393443  \n",
       "32    0.109027     0.543033  \n",
       "68    0.109027     0.543033  \n",
       "176   0.109027     0.543033  \n",
       "65    0.111255     0.497951  \n",
       "101   0.126609     0.325137  \n",
       "62    0.106215     0.563525  \n",
       "26    0.106215     0.563525  \n",
       "170   0.106215     0.563525  \n",
       "23    0.278481     0.111339  \n",
       "74    0.259259     0.114071  \n",
       "92    0.259259     0.114071  \n",
       "76    0.250000     0.112022  \n",
       "91    0.348837     0.096311  \n",
       "173   0.108209     0.374317  \n",
       "163   0.318182     0.098361  \n",
       "19    0.318182     0.098361  \n",
       "113   0.318182     0.098361  \n",
       "34    0.108511     0.338798  \n",
       "59    0.285714     0.101776  \n",
       "149   0.216216     0.116120  \n",
       "127   0.366667     0.092896  \n",
       "55    0.314286     0.096311  \n",
       "167   0.220339     0.109973  \n",
       "131   0.200000     0.107923  \n",
       "126   0.250000     0.096995  \n",
       "108   0.241379     0.097678  \n",
       "144   0.260870     0.094945  \n",
       "142   0.090491     0.816940  \n",
       "0     0.260870     0.094945  \n",
       "18    0.238095     0.094945  \n",
       "162   0.238095     0.094945  \n",
       "139   0.089136     0.893443  \n",
       "109   0.210526     0.094945  \n",
       "5     0.250000     0.091530  \n",
       "36    0.214286     0.092896  \n",
       "54    0.200000     0.093579  \n",
       "110   0.137931     0.101776  \n",
       "128   0.137931     0.101776  \n",
       "90    0.166667     0.095628  \n",
       "72    0.157895     0.096311  \n",
       "73    0.181818     0.092213  \n",
       "1     0.142857     0.094262  \n",
       "145   0.142857     0.094262  \n",
       "133   0.087950     0.900273  \n",
       "70    0.102041     0.114071  \n",
       "132   0.087791     0.908470  \n",
       "56    0.111111     0.096995  \n",
       "38    0.111111     0.096995  \n",
       "136   0.087611     0.910519  \n",
       "41    0.111111     0.092213  \n",
       "35    0.111111     0.092213  \n",
       "37    0.090909     0.093579  \n",
       "112   0.000000     0.087432  \n",
       "94    0.000000     0.087432  \n",
       "105   0.000000     0.087432  \n",
       "140   0.000000     0.087432  \n",
       "141   0.000000     0.087432  \n",
       "99    0.000000     0.087432  \n",
       "98    0.000000     0.087432  \n",
       "77    0.000000     0.087432  \n",
       "148   0.000000     0.087432  \n",
       "135   0.000000     0.087432  \n",
       "69    0.000000     0.087432  \n",
       "130   0.000000     0.087432  \n",
       "40    0.000000     0.087432  \n",
       "107   0.000000     0.087432  \n",
       "179   0.000000     0.087432  \n",
       "58    0.000000     0.087432  \n",
       "63    0.000000     0.087432  \n",
       "33    0.000000     0.087432  \n",
       "166   0.000000     0.087432  \n",
       "177   0.000000     0.087432  \n",
       "4     0.000000     0.087432  \n",
       "22    0.000000     0.087432  \n",
       "171   0.000000     0.087432  \n",
       "27    0.000000     0.087432  \n",
       "29    0.000000     0.087432  \n",
       "138   0.087432     0.912568  \n",
       "71    0.000000     0.088115  \n",
       "178   0.084507     0.127732  \n",
       "104   0.000000     0.089481  \n",
       "137   0.031390     0.230191  \n",
       "134   0.019259     0.530738  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result.sort_values('PSS',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
